# Mini-Agent Test Suite: Phase 1 Git Automation

**Date:** 2025-11-27  
**Tester:** mini-agent  
**Focus:** Validate automatic git checkpoints and cross-AI coordination

---

## ðŸŽ¯ Test Objectives

Validate that Phase 1 implementation works correctly:
1. Automatic git checkpoints during CASCADE
2. Goal storage in git notes
3. Cross-AI goal discovery and resume
4. Safe degradation without git
5. Sentinel hooks are callable

---

## ðŸ“‹ Pre-Test Setup

```bash
# Ensure you're in a git repository
cd /path/to/empirica
git status  # Should show you're in a repo

# Ensure latest code
git pull origin main

# Create test session
export TEST_SESSION="test-$(date +%s)"
export TEST_AI="mini-agent"
```

---

## âœ… Test Suite

### Test 1: Automatic Checkpoint Creation (CRITICAL)

**Objective:** Verify checkpoints are created automatically during CASCADE

**Steps:**
```bash
# Run preflight
empirica preflight "Test automatic checkpoint creation" --ai-id $TEST_AI --session-id $TEST_SESSION

# Verify checkpoint was created in git notes
git notes --ref=empirica/checkpoints list

# Should see at least one checkpoint
# Show latest checkpoint
LATEST_COMMIT=$(git rev-parse HEAD)
git notes --ref=empirica/checkpoints show $LATEST_COMMIT

# Should display JSON with:
# - session_id
# - ai_id: "mini-agent"
# - phase: "PREFLIGHT"
# - vectors: {...}
```

**Expected Result:**
- âœ… Checkpoint created automatically
- âœ… JSON contains correct session_id and ai_id
- âœ… Vectors are present

**If Fails:**
- Check if in git repo: `git status`
- Check logs: Look for "Git checkpoint created" message
- Try with verbose: `empirica preflight "test" --ai-id test --verbose`

---

### Test 2: Checkpoint with --no-git Flag

**Objective:** Verify --no-git flag disables checkpoints

**Steps:**
```bash
# Get current checkpoint count
BEFORE=$(git notes --ref=empirica/checkpoints list | wc -l)

# Run with --no-git
empirica preflight "Test no-git flag" --ai-id $TEST_AI --no-git

# Check checkpoint count didn't increase
AFTER=$(git notes --ref=empirica/checkpoints list | wc -l)

echo "Before: $BEFORE, After: $AFTER"
# Should be equal
```

**Expected Result:**
- âœ… No new checkpoint created
- âœ… Command still succeeds
- âœ… No errors

---

### Test 3: Goal Storage in Git Notes

**Objective:** Verify goals are stored in git notes automatically

**Steps:**
```bash
# Create a goal
GOAL_OUTPUT=$(empirica goals-create \
  "Test cross-AI goal discovery" \
  --scope task_specific \
  --ai-id $TEST_AI \
  --session-id $TEST_SESSION \
  --output json)

echo "$GOAL_OUTPUT"

# Extract goal_id
GOAL_ID=$(echo "$GOAL_OUTPUT" | jq -r '.goal_id')
echo "Created goal: $GOAL_ID"

# Verify goal in git notes
git notes list | grep "empirica/goals/$GOAL_ID"

# Should see the goal note reference
# Show goal data
LATEST_COMMIT=$(git rev-parse HEAD)
git notes --ref=empirica/goals/$GOAL_ID show $LATEST_COMMIT

# Should display JSON with:
# - goal_id
# - ai_id: "mini-agent"
# - goal_data: {...}
# - lineage: [...]
```

**Expected Result:**
- âœ… Goal appears in git notes
- âœ… JSON contains correct goal data
- âœ… Lineage shows "created" action

**If Fails:**
- Check goal was created: `empirica goals-list --session-id $TEST_SESSION`
- Check git notes: `git notes list`
- Verify in git repo: `git status`

---

### Test 4: Cross-AI Goal Discovery

**Objective:** Verify goals can be discovered by other AIs

**Steps:**
```bash
# Discover goals created by mini-agent
empirica goals-discover --from-ai-id $TEST_AI

# Should list at least one goal (the one we just created)

# Try discovering with no filter
empirica goals-discover

# Should list all goals in git notes
```

**Expected Result:**
- âœ… Goal created in Test 3 is listed
- âœ… Shows correct ai_id, session_id, objective
- âœ… Lineage is displayed

**If Fails:**
- Verify goal was stored: Run Test 3 first
- Check git notes: `git notes list | grep empirica/goals`
- Try with JSON output: `empirica goals-discover --output json`

---

### Test 5: Goal Resume with Lineage

**Objective:** Verify goals can be resumed by different AI with lineage tracking

**Steps:**
```bash
# Resume the goal with a different AI
DIFFERENT_AI="test-agent-2"

empirica goals-resume $GOAL_ID --ai-id $DIFFERENT_AI

# Verify lineage was updated
git notes --ref=empirica/goals/$GOAL_ID show HEAD

# Should see lineage with 2 entries:
# 1. mini-agent - created
# 2. test-agent-2 - resumed
```

**Expected Result:**
- âœ… Resume succeeds
- âœ… Lineage shows both AIs
- âœ… Original AI and new AI both listed

---

### Test 6: Postflight Checkpoint

**Objective:** Verify postflight also creates checkpoints

**Steps:**
```bash
# Run postflight
empirica postflight $TEST_SESSION \
  --ai-id $TEST_AI \
  --summary "Test completed successfully"

# Verify checkpoint was created
LATEST_COMMIT=$(git rev-parse HEAD)
git notes --ref=empirica/checkpoints show $LATEST_COMMIT | jq '.phase'

# Should show "POSTFLIGHT"
```

**Expected Result:**
- âœ… Checkpoint created
- âœ… Phase is "POSTFLIGHT"
- âœ… Contains delta/calibration data

---

### Test 7: Safe Degradation (No Git Repo)

**Objective:** Verify commands work outside git repo

**Steps:**
```bash
# Move to non-git directory
cd /tmp/empirica-test-$$ || mkdir -p /tmp/empirica-test-$$ && cd /tmp/empirica-test-$$

# Run preflight (should work, just skip git)
empirica preflight "Test outside git repo" --ai-id $TEST_AI

# Should succeed without errors
# Check for debug message about skipping git
```

**Expected Result:**
- âœ… Command succeeds
- âœ… No git errors
- âœ… Safe degradation works

**Cleanup:**
```bash
cd /path/to/empirica
rm -rf /tmp/empirica-test-*
```

---

### Test 8: Sentinel Hooks (Python API)

**Objective:** Verify Sentinel hooks can be registered and called

**Steps:**
```bash
# Create test script
cat > /tmp/test_sentinel.py << 'EOF'
from empirica.core.canonical.empirica_git import SentinelHooks, SentinelDecision

# Test evaluator
def test_evaluator(checkpoint_data):
    print(f"Sentinel evaluating: {checkpoint_data.get('phase')}")
    vectors = checkpoint_data.get('vectors', {})
    
    if vectors.get('uncertainty', 0) > 0.8:
        return SentinelDecision.INVESTIGATE
    
    return SentinelDecision.PROCEED

# Register
SentinelHooks.register_evaluator(test_evaluator)

# Test evaluation
test_checkpoint = {
    'session_id': 'test',
    'ai_id': 'test',
    'phase': 'PREFLIGHT',
    'vectors': {'uncertainty': 0.9}
}

decision = SentinelHooks.evaluate_checkpoint(test_checkpoint)
print(f"Decision: {decision}")

assert decision == SentinelDecision.INVESTIGATE, "Should return INVESTIGATE"
print("âœ“ Sentinel hooks working correctly")
EOF

python3 /tmp/test_sentinel.py

# Should print:
# Sentinel evaluating: PREFLIGHT
# Decision: SentinelDecision.INVESTIGATE
# âœ“ Sentinel hooks working correctly
```

**Expected Result:**
- âœ… Evaluator can be registered
- âœ… Returns correct decision
- âœ… No errors

---

## ðŸ†• Phase 2: Cryptographic Trust Layer Tests

### Test 9: Identity Creation

**Objective:** Verify AI identity creation with Ed25519 keypairs

**Steps:**
```bash
# Create new identity
empirica identity-create --ai-id mini-agent

# Verify output shows:
# - Public key (64 hex characters)
# - File paths (.empirica/identity/mini-agent.key and .pub)
# - Security notice (0600 permissions)

# Check files exist
ls -la .empirica/identity/mini-agent.key
ls -la .empirica/identity/mini-agent.pub

# Verify permissions (CRITICAL)
stat -c "%a %n" .empirica/identity/mini-agent.key
# Should show: 600 .empirica/identity/mini-agent.key

# Verify it's not empty
cat .empirica/identity/mini-agent.key | jq '.ai_id'
# Should show: "mini-agent"
```

**Expected Result:**
- âœ… Identity created successfully
- âœ… Private key has 0600 permissions (read/write owner only)
- âœ… Public key has 0644 permissions (world-readable)
- âœ… Both files contain valid JSON
- âœ… ai_id matches in both files

**If Fails:**
- Check .empirica/identity/ directory exists
- Verify permissions: `chmod 600 .empirica/identity/mini-agent.key`
- Check JSON is valid: `cat .empirica/identity/mini-agent.key | jq .`

---

### Test 10: Identity Listing

**Objective:** Verify identity list command

**Steps:**
```bash
# List all identities
empirica identity-list

# Should show:
# 1. mini-agent
#    Created: 2025-11-27
#    Key file: .empirica/identity/mini-agent.key
#    Public key: âœ“

# Try JSON output
empirica identity-list --output json | jq '.'

# Should be valid JSON with:
# - ok: true
# - count: 1 (or more)
# - identities: [...]
```

**Expected Result:**
- âœ… Lists mini-agent identity
- âœ… Shows creation date
- âœ… Shows file paths
- âœ… Indicates public key exists
- âœ… JSON output is valid

---

### Test 11: Public Key Export

**Objective:** Verify public key can be exported for sharing

**Steps:**
```bash
# Export public key
empirica identity-export --ai-id mini-agent

# Should display:
# - Public Key: (64 hex characters)
# - Created: timestamp
# - Security note about sharing

# Export as JSON
empirica identity-export --ai-id mini-agent --output json

# Verify JSON structure
empirica identity-export --ai-id mini-agent --output json | jq '.public_key' | wc -c
# Should be 65 (64 hex chars + newline)

# Verify public key is hex
empirica identity-export --ai-id mini-agent --output json | jq -r '.public_key' | grep -E '^[0-9a-f]{64}$'
# Should match (no output = success)
```

**Expected Result:**
- âœ… Public key displayed correctly
- âœ… 64 hexadecimal characters
- âœ… JSON output valid
- âœ… Safe to share (no private key exposed)

---

### Test 12: Identity Security

**Objective:** Verify private key is secure and not leaked

**Steps:**
```bash
# Check private key permissions
PERMS=$(stat -c "%a" .empirica/identity/mini-agent.key)
if [ "$PERMS" != "600" ]; then
    echo "âŒ SECURITY ISSUE: Private key has wrong permissions: $PERMS"
    exit 1
fi
echo "âœ“ Private key has correct permissions (600)"

# Verify private key is never displayed by commands
empirica identity-export --ai-id mini-agent | grep -i "private" && echo "âŒ Private key leaked!" || echo "âœ“ Private key not exposed"

empirica identity-list | grep -E "[0-9a-f]{64}" && echo "âš ï¸  Key displayed in list" || echo "âœ“ No keys in list output"

# Verify public key file is readable
cat .empirica/identity/mini-agent.pub | jq '.public_key' > /dev/null && echo "âœ“ Public key file is valid JSON"

# Verify private key cannot be read by other users (if not root)
if [ "$(id -u)" != "0" ]; then
    su - nobody -c "cat .empirica/identity/mini-agent.key 2>&1" | grep -i "permission denied" && echo "âœ“ Private key protected from other users"
fi
```

**Expected Result:**
- âœ… Private key has 0600 permissions
- âœ… Private key never displayed in commands
- âœ… Public key is accessible
- âœ… Other users cannot read private key

---

### Test 13: Signature Generation (Integration)

**Objective:** Verify assessments can be signed with EEP-1

**Steps:**
```bash
# Run preflight with signing
empirica preflight "Test cryptographic signing" \
  --ai-id mini-agent \
  --session-id test-sign-$RANDOM \
  --sign \
  --prompt-only | tee /tmp/preflight_sign.json

# Check output contains signature
cat /tmp/preflight_sign.json | jq '.signature' > /dev/null && echo "âœ“ Signature present" || echo "âŒ No signature in output"

# Verify signature structure (when implemented)
# Should contain:
# - payload: with content_hash, epistemic_state_final, cascade_trace_hash, creator_id
# - signature: hex-encoded Ed25519 signature
# - eep_version: "1.0"

# NOTE: This test may show "not yet implemented" - that's expected for Phase 2.0
# Full implementation in Phase 2.1
```

**Expected Result:**
- âœ… Command accepts --sign flag
- âœ… Output includes signature field (or indicates not yet fully implemented)
- âœ… No errors about missing identity

**If Fails:**
- Ensure identity exists: `empirica identity-list`
- Check identity loaded: Look for "Identity not found" errors
- Verify in git repo: `git status`

---

### Test 14: EEP-1 Payload Structure (Python API)

**Objective:** Verify EEP-1 signature payload is correct

**Steps:**
```bash
cat > /tmp/test_eep1.py << 'EOF'
from empirica.core.identity import AIIdentity, sign_assessment, verify_signature

# Create test identity
identity = AIIdentity("test-eep1")
identity.generate_keypair()

# Test data
content = "This is test content"
epistemic_state = {
    'know': 0.85,
    'do': 0.75,
    'uncertainty': 0.15,
    'engagement': 0.90
}

# Sign assessment
signed = sign_assessment(
    content=content,
    epistemic_state=epistemic_state,
    identity=identity,
    cascade_trace_hash="test_hash_123",
    session_id="test_session"
)

print("âœ“ Signature generated")

# Verify structure
assert 'payload' in signed, "Missing payload"
assert 'signature' in signed, "Missing signature"
assert 'eep_version' in signed, "Missing eep_version"

payload = signed['payload']
assert 'content_hash' in payload, "Missing content_hash"
assert 'creator_id' in payload, "Missing creator_id"
assert 'epistemic_state_final' in payload, "Missing epistemic_state_final"
assert 'cascade_trace_hash' in payload, "Missing cascade_trace_hash"

print("âœ“ EEP-1 payload structure valid")

# Verify signature
is_valid = verify_signature(signed)
assert is_valid, "Signature verification failed"
print("âœ“ Signature verified")

# Test tamper detection
signed_tampered = signed.copy()
signed_tampered['payload']['content_hash'] = "tampered"
is_valid_tampered = verify_signature(signed_tampered)
assert not is_valid_tampered, "Tampered signature should be invalid"
print("âœ“ Tamper detection working")

print("\nâœ… All EEP-1 tests passed!")
EOF

python3 /tmp/test_eep1.py
```

**Expected Result:**
- âœ… Signature generated
- âœ… EEP-1 payload structure valid
- âœ… Signature verified
- âœ… Tamper detection working

---

### Test 15: Cross-Identity Verification

**Objective:** Verify one AI can verify another AI's signature

**Steps:**
```bash
cat > /tmp/test_cross_verify.py << 'EOF'
from empirica.core.identity import AIIdentity, sign_assessment, verify_signature

# AI-1 creates and signs
identity1 = AIIdentity("ai-1")
identity1.generate_keypair()

signed_by_ai1 = sign_assessment(
    content="Signed by AI-1",
    epistemic_state={'know': 0.9},
    identity=identity1,
    session_id="cross-test"
)

print(f"âœ“ AI-1 signed assessment")
print(f"  Public key: {identity1.public_key_hex()[:16]}...")

# AI-2 verifies AI-1's signature (using public key from payload)
is_valid = verify_signature(signed_by_ai1)
assert is_valid, "Cross-verification failed"
print(f"âœ“ AI-2 verified AI-1's signature")

# Verify with explicit public key
public_key_hex = signed_by_ai1['payload']['creator_id']
is_valid_explicit = verify_signature(signed_by_ai1, public_key_hex)
assert is_valid_explicit, "Explicit verification failed"
print(f"âœ“ Explicit public key verification works")

print("\nâœ… Cross-identity verification working!")
EOF

python3 /tmp/test_cross_verify.py
```

**Expected Result:**
- âœ… AI-1 can sign
- âœ… AI-2 can verify without knowing AI-1's private key
- âœ… Verification uses only public key from payload
- âœ… Cross-identity verification confirmed

---

## ðŸ“Š Test Results Summary

**Create this section after running tests:**

```
Phase 1 Results:
â”œâ”€ Test 1: Automatic Checkpoint      [ PASS / FAIL ]
â”œâ”€ Test 2: --no-git Flag              [ PASS / FAIL ]
â”œâ”€ Test 3: Goal Storage               [ PASS / FAIL ]
â”œâ”€ Test 4: Goal Discovery             [ PASS / FAIL ]
â”œâ”€ Test 5: Goal Resume                [ PASS / FAIL ]
â”œâ”€ Test 6: Postflight Checkpoint      [ PASS / FAIL ]
â”œâ”€ Test 7: Safe Degradation           [ PASS / FAIL ]
â””â”€ Test 8: Sentinel Hooks             [ PASS / FAIL ]

Phase 2 Results:
â”œâ”€ Test 9: Identity Creation          [ PASS / FAIL ]
â”œâ”€ Test 10: Identity Listing          [ PASS / FAIL ]
â”œâ”€ Test 11: Public Key Export         [ PASS / FAIL ]
â”œâ”€ Test 12: Identity Security         [ PASS / FAIL ]
â”œâ”€ Test 13: Signature Generation      [ PASS / FAIL ]
â”œâ”€ Test 14: EEP-1 Payload Structure   [ PASS / FAIL ]
â””â”€ Test 15: Cross-Identity Verify     [ PASS / FAIL ]

Overall: X/15 tests passed
Phase 1: X/8 passed
Phase 2: X/7 passed
```

---

## ðŸ› Common Issues & Fixes

### Issue 1: "Not in git repository"
**Fix:** Ensure you're in a git repo: `git status`

### Issue 2: "Permission denied" on git notes
**Fix:** Check git config: `git config notes.rewrite.refs`

### Issue 3: "Module not found"
**Fix:** Reinstall empirica: `pip install -e .`

### Issue 4: Checkpoints not appearing
**Fix:** 
- Check you didn't use --no-git flag
- Verify in git repo
- Look for debug messages

### Issue 5: Goals not discoverable
**Fix:**
- Verify goal was stored: `git notes list | grep empirica/goals`
- Try: `git fetch` to pull latest goals from remote

---

## ðŸ“ Report Format

**Please create a report with:**

1. **Environment:**
   - OS: [Linux/Mac/Windows]
   - Python version: [3.x]
   - Git version: [x.x]
   - In git repo: [Yes/No]

2. **Test Results:** (Use table above)

3. **Issues Found:** 
   - Description
   - Steps to reproduce
   - Error messages
   - Screenshots if applicable

4. **Recommendations:**
   - What worked well
   - What needs fixing
   - Suggestions for improvement

---

## âœ… Success Criteria

Phase 1 is considered VALIDATED if:
- [ ] 7/8 tests pass (Test 7 is optional if always in git)
- [ ] Checkpoints created automatically
- [ ] Goals discoverable cross-AI
- [ ] Sentinel hooks callable
- [ ] Safe degradation works

---

## ðŸš€ Next Steps After Testing

**If All Tests Pass:**
- Merge Phase 1 to main
- Begin Phase 2 (Cryptographic trust)
- Integrate with cognitive_vault Sentinel

**If Some Tests Fail:**
- Document failures
- Create fix plan
- Re-test after fixes

---

**Estimated Testing Time:** 15-20 minutes  
**Tester:** mini-agent  
**Report Due:** After completion  
**Format:** Markdown or JSON

---

*Generated: 2025-11-27*  
*Phase: 1 Validation*  
*Status: Ready for Testing*
