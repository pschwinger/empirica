# Empirica Epistemic Learning System

## The Vision

Empirica is not just a workflow framework - it's a **continuous epistemic learning system** that enables AI agents to autonomously improve through:

1. **Capturing problems** without interrupting flow
2. **Storing knowledge** with semantic embeddings
3. **Learning patterns** across sessions
4. **Making better decisions** based on past experience
5. **Improving collaboratively** across multiple AI agents

## The 5-Layer Knowledge Graph

Every project accumulates knowledge across these five layers:

### Layer 1: FINDINGS
**What we discovered that works**
- "Implemented OAuth2 with JWT tokens"
- "Connection pooling reduces latency by 60%"
- Stored in: `project_findings` table
- Semantic: Success patterns, what to replicate

### Layer 2: UNKNOWNS
**What we don't know yet**
- "Token refresh mechanism unclear"
- "Performance bottleneck not identified"
- Stored in: `project_unknowns` table
- Semantic: Knowledge gaps, investigation targets

### Layer 3: ISSUES (Auto-Captured)
**Problems we encountered and how we handled them**
- "CHECK-SUBMIT doesn't support stdin JSON" â†’ RESOLVED
- "Database timeout under load" â†’ HANDOFF to specialist
- "CLI commands lack config file support" â†’ WONTFIX (by design)
- Stored in: `auto_captured_issues` table
- Semantic: Anti-patterns, what NOT to do, learning history

### Layer 4: MISTAKES
**Things we tried that didn't work**
- "Tried WebSocket approach - too complex"
- "Attempted connection pooling with HikariCP - caused deadlocks"
- Stored in: `mistakes_made` table
- Semantic: Dead ends, failed approaches

### Layer 5: DEAD ENDS
**Architectural decisions and why they were rejected**
- "Investigated REST caching - incompatible with real-time requirements"
- "Considered microservices - overengineering for this scale"
- Stored in: `project_dead_ends` table
- Semantic: Design tradeoffs, architectural constraints

## How Issues Drive Learning

### Issue Lifecycle = Learning Progression

```
NEW
â”œâ”€ "Problem discovered, no action yet"
â”œâ”€ Semantic: "This exists and needs attention"
â””â”€ AI thinks: "Should I work on this?"

â†“

INVESTIGATING
â”œâ”€ "AI actively working on it"
â”œâ”€ Semantic: "Someone is handling this"
â””â”€ Next AI thinks: "This is being addressed"

â†“

RESOLVED
â”œâ”€ "AI X fixed this on [date]"
â”œâ”€ Semantic: "Problem solved by approach X"
â”œâ”€ Includes: resolution notes with what worked
â””â”€ Next AI thinks: "If I see this again, try X first"

OR

HANDOFF
â”œâ”€ "AI X couldn't finish, marking for specialist"
â”œâ”€ Semantic: "Requires expertise, context preserved"
â””â”€ Specialist AI thinks: "Here's what was already tried"

OR

WONTFIX
â”œâ”€ "Intentional decision not to fix"
â”œâ”€ Semantic: "Known issue, but acceptable/out-of-scope"
â””â”€ Next AI thinks: "This is a known constraint"
```

## The Continuous Learning Loop

### Session N: Foundation
```
AI-1 works on Feature X
â”œâ”€ Discovers: "CLI stdin support missing"
â”œâ”€ Auto-captures: BUG, severity=HIGH
â”œâ”€ Fixes it: Adds config file parsing
â”œâ”€ Marks: RESOLVED, resolution="Added parser"
â””â”€ Result: Knowledge stored + vectorized
```

### Session N+1: Learning
```
AI-2 starts work on Related Feature Y
â”œâ”€ Runs project-bootstrap
â”œâ”€ Sees: "Recent issue: CLI stdin support"
â”œâ”€ Semantic search: "CLI JSON issues"
â”œâ”€ Finds: "Someone solved similar problem"
â”œâ”€ Applies: Same fix pattern to their work
â””â”€ Result: Leverages past learning, faster completion
```

### Session N+2: Pattern Recognition
```
AI-3 analyzes all accumulated issues
â”œâ”€ Detects pattern: "stdin JSON missing in 5 commands"
â”œâ”€ Semantic grouping: Related issues clustered
â”œâ”€ Proposes: Systemic solution, not one-offs
â””â”€ Result: Project-level improvement from accumulated learning
```

### Session N+3: Autonomous Improvement
```
AI-4 makes decisions informed by entire history
â”œâ”€ Knows: What's been tried, what worked, what failed
â”œâ”€ Semantic understanding: "These patterns lead to issues"
â”œâ”€ Makes proactive decisions: "Avoid that approach"
â””â”€ Result: Continuous autonomous improvement
```

## Technical Architecture

### Storage Layers

```
Memory Layers (Atomic Write)
â”œâ”€â”€ SQLite (Queryable)
â”‚   â””â”€â”€ auto_captured_issues table
â”‚       â”œâ”€â”€ id, session_id, category, severity
â”‚       â”œâ”€â”€ status (new/investigating/resolved/wontfix)
â”‚       â””â”€â”€ resolution notes
â”‚
â”œâ”€â”€ Git Notes (Immutable Audit Trail)
â”‚   â””â”€â”€ refs/issues/... (optional)
â”‚       â””â”€â”€ Signed, versioned issue checkpoints
â”‚
â””â”€â”€ Qdrant Vectors (Semantic Search)
    â””â”€â”€ Issue embeddings
        â”œâ”€â”€ Semantic similarity
        â”œâ”€â”€ Pattern detection
        â””â”€â”€ Cross-session learning
```

### Query Patterns

```python
# Current: Direct queries
issues = service.list_issues(status="resolved", category="bug")

# Future: Semantic queries (Qdrant Phase 3)
similar_issues = qdrant.search(
    query="database performance problems",
    limit=5
)
# Returns: Issues semantically related to query

# Future: Pattern detection
patterns = qdrant.analyze(
    project_id="...",
    time_window="30 days"
)
# Returns: Emerging patterns, anti-patterns
```

## Integration with CASCADE

### PREFLIGHT Phase
- Set baseline: "What we know before starting"
- Not directly related to issues

### CHECK Phase
- Display active issues as context
- "Here are problems we've encountered"
- Informs confidence decision

### POSTFLIGHT Phase
- Issues created during session are logged
- Next AI sees: "This is what was tried"

### project-bootstrap
- Shows findings + unknowns + active issues
- Next AI sees full epistemic state
- Enables informed decision-making

## Semantic Retrieval Examples

### Example 1: Avoid Duplicate Work
```
New AI encounters: Timeout in database queries
â”œâ”€ Semantic search: "database performance issues"
â”œâ”€ Finds: "Performance issue: Query took 2500ms (expected 500ms)"
â”œâ”€ Finds resolution: "Implemented connection pooling"
â””â”€ AI learns: "Try connection pooling first"
```

### Example 2: Learn From Anti-patterns
```
AI considers: Using WebSocket approach
â”œâ”€ Semantic search: "WebSocket patterns"
â”œâ”€ Finds mistake: "Tried WebSocket - too complex"
â”œâ”€ Finds detail: "REST polling was better fit"
â””â”€ AI learns: "Avoid WebSocket for this use case"
```

### Example 3: Cross-AI Knowledge Transfer
```
AI-1 session ends: "Here's what I couldn't finish"
â”œâ”€ Issue marked: HANDOFF, assigned_to="ai-optimizer"
â”œâ”€ Includes: Full context, stack trace, attempted fixes
â”‚
AI-2 session starts: Gets bootstrap
â”œâ”€ Sees: "Pending optimization work with full context"
â”œâ”€ No re-investigation needed
â””â”€ Can start immediately where AI-1 left off
```

## Current Implementation Status

### âœ… Phase 1: Core Capture (COMPLETE)
- Issue capture service: `empirica/core/issue_capture.py`
- 6 CLI commands: issue-list, issue-show, issue-handoff, issue-resolve, issue-export, issue-stats
- Database schema: `auto_captured_issues` table
- Handoff workflow: Export/import with full context

### ğŸ”„ Phase 2: CASCADE Integration (IN PROGRESS)
- Add issues to project-bootstrap output
- Display active issues in CHECK gate
- Auto-capture errors during CASCADE phases

### ğŸ“‹ Phase 3: Qdrant Integration (PLANNED)
- Embed all issues with semantic vectors
- Implement semantic search across issues
- Pattern detection across sessions
- Cross-AI knowledge transfer optimization

### ğŸ“‹ Phase 4: Learning Analytics (PLANNED)
- Track which resolutions were actually helpful
- Measure pattern recognition effectiveness
- Generate project health metrics
- Autonomous improvement measurement

## Decision: Storage Semantics

### What Gets Stored
âœ… All issues (never deleted)
âœ… Status history (audit trail)
âœ… Resolution notes (what worked)
âœ… Who fixed it and when
âœ… Full semantic embeddings

### What Gets Shown in bootstrap
âœ… Active issues (new/investigating/handoff)
âœ… Recently resolved (last 30 days)
âœ… Critical bugs (severity=blocker)
âš ï¸ Old resolved (summary count only)

### What Never Gets Deleted
âœ… Issues marked resolved (not deleted)
âœ… Mistakes logged (not hidden)
âœ… Dead ends documented (not removed)
âœ… Complete audit trail preserved

**Rationale**: Learning requires history. Deleting resolved issues removes the learning value.

## Why This Matters

### Without Auto-Capture
- Each AI rediscovers the same problems
- Context lost between sessions
- No continuous improvement
- Knowledge siloed per AI

### With Auto-Capture + Semantic Learning
- **Efficiency**: Don't repeat others' work
- **Quality**: Learn from mistakes
- **Coordination**: Seamless multi-AI handoffs
- **Autonomy**: Improve without human guidance
- **Resilience**: Knowledge survives AI changes

## Next Steps

1. **Integrate issues into project-bootstrap** (next session)
2. **Auto-capture CASCADE errors** (next session)
3. **Implement Qdrant semantic search** (future)
4. **Build learning analytics** (future)
5. **Measure autonomous improvement** (future)

---

**Core Principle**: Every problem encountered is a learning opportunity. By capturing and storing it epistemically, the system enables continuous autonomous improvement across all future work.
