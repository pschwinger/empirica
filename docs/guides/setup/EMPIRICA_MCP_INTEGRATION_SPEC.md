# üåê EMPIRICA MCP SERVER - COMPLETE INTEGRATION SPECIFICATION

**Status**: Deep Dive Analysis Complete  
**Purpose**: Map all Empirica components to MCP tools and identify gaps  
**Action Required**: Adapt MCP server to expose all 4 core components + CLI tools

---

## üéØ EXECUTIVE SUMMARY

### **Current State Analysis**
- **‚úÖ Components Working**: All 4 core components are operational with full APIs
- **‚ö†Ô∏è MCP Server Gaps**: Current MCP server has 54 tools but missing direct integration with core components
- **üîß Action Required**: Add MCP tools for autonomous_goal_orchestrator, adaptive_uncertainty_calibration, metacognition_12d_monitor, and metacognitive_cascade
- **üìã CLI Integration**: Need to expose full CLI command set through MCP

### **Priority Components for MCP Integration**
1. **Metacognitive Cascade** (SimpleCascade) - 8 methods available
2. **12D Metacognition Monitor** (TwelveVectorSelfAwarenessMonitor) - 6 methods available  
3. **Adaptive Uncertainty Calibration** (AdaptiveUncertaintyCalibration) - 3 methods available
4. **Autonomous Goal Orchestrator** (enhanced_orchestrate_with_context) - 3 functions available

---

## üìä COMPONENT API INVENTORY - COMPLETE MAPPING

### **1. METACOGNITIVE CASCADE (SimpleCascade)**
**Status**: ‚úÖ Component Working | ‚ùå Not in MCP Server | üî¥ HIGH PRIORITY

#### **Available Methods**
```python
from metacognitive_cascade.metacognitive_cascade import SimpleCascade

cascade = SimpleCascade()

# Primary Method (MOST IMPORTANT)
cascade.run_full_cascade(question: str, context: dict = None) -> dict
# Returns: Complete cascade result with all 5 phases

# Individual Phase Methods
cascade.think(question: str) -> dict                # THINK phase
cascade.assess_uncertainty(context: dict) -> dict   # UNCERTAINTY phase
cascade.check(context: dict) -> dict                # CHECK phase
cascade.investigate(context: dict) -> dict          # INVESTIGATE phase
cascade.act(decision_context: dict) -> dict         # ACT phase

# Learning & Calibration
cascade.provide_feedback(outcome: dict) -> dict     # Learn from outcomes
cascade.get_calibration_status() -> dict            # Current calibration
```

#### **MCP Tool Specification**
```json
{
  "name": "empirica.cascade.run_full",
  "description": "Run complete metacognitive cascade (THINK‚ÜíUNCERTAINTY‚ÜíCHECK‚ÜíINVESTIGATE‚ÜíACT)",
  "inputSchema": {
    "type": "object",
    "properties": {
      "question": {"type": "string", "description": "Decision or question to analyze"},
      "context": {"type": "object", "description": "Additional context (optional)"}
    },
    "required": ["question"]
  }
}

{
  "name": "empirica.cascade.phase",
  "description": "Run individual cascade phase",
  "inputSchema": {
    "type": "object",
    "properties": {
      "phase": {"type": "string", "enum": ["think", "uncertainty", "check", "investigate", "act"]},
      "input": {"type": "object", "description": "Phase-specific input"}
    },
    "required": ["phase", "input"]
  }
}

{
  "name": "empirica.cascade.feedback",
  "description": "Provide feedback for cascade learning",
  "inputSchema": {
    "type": "object",
    "properties": {
      "outcome": {"type": "object", "description": "Outcome data for learning"}
    },
    "required": ["outcome"]
  }
}
```

---

### **2. METACOGNITION 12D MONITOR (TwelveVectorSelfAwarenessMonitor)**
**Status**: ‚úÖ Component Working | ‚ùå Not in MCP Server | üî¥ HIGH PRIORITY

#### **Available Methods**
```python
from metacognition_12d_monitor.twelve_vector_self_awareness import (
    TwelveVectorSelfAwarenessMonitor,
    assess_comprehensive_self_awareness
)

# Create monitor
monitor = TwelveVectorSelfAwarenessMonitor(ai_id="agent_name")

# Primary Method (MOST IMPORTANT)
state = monitor.assess_complete_state(
    task_context: dict,           # Current task information
    user_input: str = "",         # User's input/question
    conversation_history: list = None  # Previous conversation
) -> TwelveVectorCognitiveState

# Returns object with 12 vectors:
# - know_vector, do_vector, context_vector (Epistemic Uncertainty)
# - clarity_vector, coherence_vector, depth_vector, signal_vector (Comprehension)
# - state_vector, change_vector, completion_vector, impact_vector (Execution)
# - engagement_vector (NEW: Engagement dimension)

# Additional Methods
engagement = monitor.assess_engagement(context: dict) -> EngagementDimension
summary = monitor.format_twelve_vector_summary() -> str
recommendations = monitor.get_engagement_recommendations() -> List[str]

# Convenience Function
state = assess_comprehensive_self_awareness(
    task_context: dict,
    user_input: str = "",
    conversation_history: list = None
) -> TwelveVectorCognitiveState
```

#### **MCP Tool Specification**
```json
{
  "name": "empirica.monitor.assess_12d",
  "description": "Assess complete 12-dimensional cognitive state (epistemic, comprehension, execution, engagement)",
  "inputSchema": {
    "type": "object",
    "properties": {
      "ai_id": {"type": "string", "description": "AI agent identifier"},
      "task_context": {"type": "object", "description": "Current task context"},
      "user_input": {"type": "string", "description": "User input/question (optional)"},
      "conversation_history": {"type": "array", "items": {"type": "string"}, "description": "Previous conversation (optional)"}
    },
    "required": ["ai_id", "task_context"]
  }
}

{
  "name": "empirica.monitor.assess_engagement",
  "description": "Assess engagement dimension specifically",
  "inputSchema": {
    "type": "object",
    "properties": {
      "ai_id": {"type": "string"},
      "context": {"type": "object"}
    },
    "required": ["ai_id", "context"]
  }
}

{
  "name": "empirica.monitor.get_summary",
  "description": "Get formatted 13-vector summary",
  "inputSchema": {
    "type": "object",
    "properties": {
      "ai_id": {"type": "string"}
    },
    "required": ["ai_id"]
  }
}
```

---

### **3. ADAPTIVE UNCERTAINTY CALIBRATION (AdaptiveUncertaintyCalibration)**
**Status**: ‚úÖ Component Working | ‚ö†Ô∏è Partial in MCP Server | üü° MEDIUM PRIORITY

#### **Available Methods**
```python
from adaptive_uncertainty_calibration.adaptive_uncertainty_calibration import (
    AdaptiveUncertaintyCalibration,
    assess_uncertainty,
    create_default_calibrator
)

# Create calibrator
calibrator = create_default_calibrator()

# Primary Method (MOST IMPORTANT)
result = calibrator.assess_uncertainty(
    decision_context: str  # Context for uncertainty assessment
) -> CalibrationResult

# CalibrationResult contains:
# - uncertainty_score: float
# - confidence_level: float
# - epistemic_uncertainty: float
# - aleatoric_uncertainty: float
# - calibration_quality: str

# Learning Methods
calibrator.receive_feedback(outcome: dict) -> None
status = calibrator.get_calibration_status() -> dict

# Convenience Function
result = assess_uncertainty(decision_context: str) -> CalibrationResult
```

#### **MCP Tool Specification**
```json
{
  "name": "empirica.calibration.assess_uncertainty",
  "description": "Assess uncertainty with adaptive calibration",
  "inputSchema": {
    "type": "object",
    "properties": {
      "decision_context": {"type": "string", "description": "Context for uncertainty assessment"}
    },
    "required": ["decision_context"]
  }
}

{
  "name": "empirica.calibration.provide_feedback",
  "description": "Provide feedback for calibration learning",
  "inputSchema": {
    "type": "object",
    "properties": {
      "outcome": {"type": "object", "description": "Outcome data"}
    },
    "required": ["outcome"]
  }
}

{
  "name": "empirica.calibration.get_status",
  "description": "Get current calibration status",
  "inputSchema": {
    "type": "object",
    "properties": {}
  }
}
```

**Note**: Current MCP server has `empirica.uncertainty.assess` but it uses AugieSDK, not the AdaptiveUncertaintyCalibration component. Need to integrate or expose both.

---

### **4. AUTONOMOUS GOAL ORCHESTRATOR**
**Status**: ‚úÖ Component Working | ‚ùå Not in MCP Server | üü° MEDIUM PRIORITY

#### **Available Functions**
```python
from autonomous_goal_orchestrator.autonomous_goal_orchestrator import (
    create_dynamic_goals,
    enhanced_orchestrate_with_context,
    DynamicContextAnalyzer
)

# Primary Functions
goals = create_dynamic_goals(context: dict) -> List[Goal]
# Create dynamic goals based on context

result = enhanced_orchestrate_with_context(
    goals: List[Goal],
    context: dict
) -> dict
# Orchestrate goals with context awareness and engagement tracking

# Context Analysis
analyzer = DynamicContextAnalyzer()
analysis = analyzer.analyze_context(context: dict) -> dict
```

#### **MCP Tool Specification**
```json
{
  "name": "empirica.goals.create_dynamic",
  "description": "Create dynamic goals based on context",
  "inputSchema": {
    "type": "object",
    "properties": {
      "context": {"type": "object", "description": "Context for goal generation"}
    },
    "required": ["context"]
  }
}

{
  "name": "empirica.goals.orchestrate",
  "description": "Orchestrate goals with engagement tracking",
  "inputSchema": {
    "type": "object",
    "properties": {
      "goals": {"type": "array", "description": "List of goals"},
      "context": {"type": "object", "description": "Orchestration context"}
    },
    "required": ["goals", "context"]
  }
}

{
  "name": "empirica.goals.analyze_context",
  "description": "Analyze context for goal orchestration",
  "inputSchema": {
    "type": "object",
    "properties": {
      "context": {"type": "object"}
    },
    "required": ["context"]
  }
}
```

---

## üìã CLI TOOL INTEGRATION

### **Current CLI Structure**
Located in `semantic_self_aware_kit/cli_components/`:
```
- assessment_commands.py     # 12D assessment commands
- bootstrap_commands.py       # Bootstrap system commands
- cascade_commands.py         # Cascade operation commands
- cli_core.py                # Core CLI framework
- cli_utils.py               # Utility functions
- component_commands.py       # Component management
- investigation_commands.py   # Investigation tools
- performance_commands.py     # Performance benchmarking
- utility_commands.py         # General utilities
```

### **CLI Commands to Expose via MCP**

#### **Bootstrap Commands**
```json
{
  "name": "empirica.cli.bootstrap",
  "description": "Bootstrap Empirica system (levels: minimal, standard, extended, complete)",
  "inputSchema": {
    "type": "object",
    "properties": {
      "level": {"type": "string", "enum": ["minimal", "standard", "extended", "complete"]},
      "options": {"type": "object"}
    },
    "required": ["level"]
  }
}
```

#### **Assessment Commands**
```json
{
  "name": "empirica.cli.assess",
  "description": "Run 13-vector self-awareness assessment via CLI",
  "inputSchema": {
    "type": "object",
    "properties": {
      "task": {"type": "string"},
      "context": {"type": "object"}
    },
    "required": ["task"]
  }
}
```

#### **Cascade Commands**
```json
{
  "name": "empirica.cli.cascade",
  "description": "Run metacognitive cascade via CLI",
  "inputSchema": {
    "type": "object",
    "properties": {
      "question": {"type": "string"},
      "options": {"type": "object"}
    },
    "required": ["question"]
  }
}
```

#### **Investigation Commands**
```json
{
  "name": "empirica.cli.investigate",
  "description": "Investigate workspace/code via CLI",
  "inputSchema": {
    "type": "object",
    "properties": {
      "target": {"type": "string"},
      "depth": {"type": "string", "enum": ["shallow", "deep"]}
    },
    "required": ["target"]
  }
}
```

#### **Performance Commands**
```json
{
  "name": "empirica.cli.performance",
  "description": "Run performance benchmarks via CLI",
  "inputSchema": {
    "type": "object",
    "properties": {
      "operation": {"type": "string"},
      "config": {"type": "object"}
    },
    "required": ["operation"]
  }
}
```

#### **Component List Command**
```json
{
  "name": "empirica.cli.list_components",
  "description": "List all available components with status and descriptions",
  "inputSchema": {
    "type": "object",
    "properties": {
      "tier": {"type": "integer", "minimum": 1, "maximum": 4},
      "category": {"type": "string"}
    }
  }
}
```

#### **Help Command**
```json
{
  "name": "empirica.cli.help",
  "description": "Get help for all CLI commands with detailed descriptions",
  "inputSchema": {
    "type": "object",
    "properties": {
      "command": {"type": "string", "description": "Specific command to get help for (optional)"}
    }
  }
}
```

---

## üîß CURRENT MCP SERVER STATUS

### **Implemented Tools (Working)**
- ‚úÖ empirica.workspace.scan - Workspace scanning
- ‚úÖ empirica.context.validate_file - File validation
- ‚úÖ empirica.web.templates.generate - Template generation
- ‚úÖ empirica.web.server.status - Server status check
- ‚úÖ empirica.uncertainty.assess - Uncertainty via AugieSDK (not component)
- ‚úÖ sentry.* - Sentry integration (3 tools)
- ‚úÖ devtools.* - Chrome DevTools integration (3 tools)
- ‚úÖ correlator.* - Sentry/Browser correlation
- ‚úÖ semantic.workspace_awareness - Workspace awareness
- ‚úÖ semantic.intelligent_navigation - Navigation planning
- ‚úÖ Many semantic component stubs (24+ tools)

### **Missing Core Components (CRITICAL)**
- ‚ùå empirica.cascade.* - Metacognitive cascade tools (0/3 tools)
- ‚ùå empirica.monitor.* - 12D monitoring tools (0/3 tools)
- ‚ö†Ô∏è empirica.calibration.* - Uncertainty calibration (partially via AugieSDK)
- ‚ùå empirica.goals.* - Goal orchestration tools (0/3 tools)
- ‚ùå empirica.cli.* - CLI command exposure (0/7 tools)

### **Stub Tools (Need Implementation)**
Many semantic component tools are stubs returning:
```python
{"ok": False, "error": "Component not yet implemented in MCP"}
```

These should either be:
1. Implemented with actual component integration
2. Removed if not needed
3. Documented as "planned future tools"

---

## üöÄ IMPLEMENTATION ROADMAP

### **Phase 1: Core Component Integration (IMMEDIATE - HIGH PRIORITY)**

#### **Task 1.1: Add Metacognitive Cascade Tools**
```python
# Add to empirica_mcp_server.py

def tool_empirica_cascade_run_full(params: Dict[str, Any]) -> Dict[str, Any]:
    """Run complete metacognitive cascade"""
    try:
        from semantic_self_aware_kit.semantic_self_aware_kit.metacognitive_cascade.metacognitive_cascade import SimpleCascade
        
        cascade = SimpleCascade()
        question = params.get("question")
        context = params.get("context", {})
        
        result = cascade.run_full_cascade(question, context)
        return {"ok": True, "result": result}
    except Exception as e:
        return {"ok": False, "error": str(e)}

def tool_empirica_cascade_phase(params: Dict[str, Any]) -> Dict[str, Any]:
    """Run individual cascade phase"""
    try:
        from semantic_self_aware_kit.semantic_self_aware_kit.metacognitive_cascade.metacognitive_cascade import SimpleCascade
        
        cascade = SimpleCascade()
        phase = params.get("phase")
        phase_input = params.get("input", {})
        
        method = getattr(cascade, phase)
        result = method(phase_input)
        return {"ok": True, "result": result}
    except Exception as e:
        return {"ok": False, "error": str(e)}

def tool_empirica_cascade_feedback(params: Dict[str, Any]) -> Dict[str, Any]:
    """Provide feedback for cascade learning"""
    try:
        from semantic_self_aware_kit.semantic_self_aware_kit.metacognitive_cascade.metacognitive_cascade import SimpleCascade
        
        cascade = SimpleCascade()
        outcome = params.get("outcome", {})
        
        cascade.provide_feedback(outcome)
        status = cascade.get_calibration_status()
        return {"ok": True, "feedback_recorded": True, "calibration_status": status}
    except Exception as e:
        return {"ok": False, "error": str(e)}
```

#### **Task 1.2: Add 12D Monitor Tools**
```python
def tool_empirica_monitor_assess_12d(params: Dict[str, Any]) -> Dict[str, Any]:
    """Assess 12-dimensional cognitive state"""
    try:
        from semantic_self_aware_kit.semantic_self_aware_kit.metacognition_12d_monitor.twelve_vector_self_awareness import TwelveVectorSelfAwarenessMonitor
        
        ai_id = params.get("ai_id", "empirica_mcp_agent")
        monitor = TwelveVectorSelfAwarenessMonitor(ai_id)
        
        task_context = params.get("task_context", {})
        user_input = params.get("user_input", "")
        conversation_history = params.get("conversation_history", None)
        
        state = monitor.assess_complete_state(task_context, user_input, conversation_history)
        
        # Convert to dict for JSON serialization
        return {
            "ok": True,
            "state": {
                "know": state.know_vector,
                "do": state.do_vector,
                "context": state.context_vector,
                "clarity": state.clarity_vector,
                "coherence": state.coherence_vector,
                "depth": state.depth_vector,
                "signal": state.signal_vector,
                "state": state.state_vector,
                "change": state.change_vector,
                "completion": state.completion_vector,
                "impact": state.impact_vector,
                "engagement": state.engagement_vector,
                "overall_confidence": state.overall_confidence
            }
        }
    except Exception as e:
        return {"ok": False, "error": str(e)}

def tool_empirica_monitor_get_summary(params: Dict[str, Any]) -> Dict[str, Any]:
    """Get formatted 13-vector summary"""
    try:
        from semantic_self_aware_kit.semantic_self_aware_kit.metacognition_12d_monitor.twelve_vector_self_awareness import TwelveVectorSelfAwarenessMonitor
        
        ai_id = params.get("ai_id", "empirica_mcp_agent")
        monitor = TwelveVectorSelfAwarenessMonitor(ai_id)
        
        summary = monitor.format_twelve_vector_summary()
        return {"ok": True, "summary": summary}
    except Exception as e:
        return {"ok": False, "error": str(e)}
```

#### **Task 1.3: Add Uncertainty Calibration Tools**
```python
def tool_empirica_calibration_assess(params: Dict[str, Any]) -> Dict[str, Any]:
    """Assess uncertainty with adaptive calibration"""
    try:
        from semantic_self_aware_kit.semantic_self_aware_kit.adaptive_uncertainty_calibration.adaptive_uncertainty_calibration import assess_uncertainty
        
        decision_context = params.get("decision_context", "")
        result = assess_uncertainty(decision_context)
        
        return {
            "ok": True,
            "uncertainty_score": result.uncertainty_score,
            "confidence_level": result.confidence_level,
            "epistemic_uncertainty": result.epistemic_uncertainty,
            "aleatoric_uncertainty": result.aleatoric_uncertainty,
            "calibration_quality": result.calibration_quality
        }
    except Exception as e:
        return {"ok": False, "error": str(e)}
```

#### **Task 1.4: Add Goal Orchestration Tools**
```python
def tool_empirica_goals_orchestrate(params: Dict[str, Any]) -> Dict[str, Any]:
    """Orchestrate goals with engagement tracking"""
    try:
        from semantic_self_aware_kit.semantic_self_aware_kit.autonomous_goal_orchestrator.autonomous_goal_orchestrator import (
            enhanced_orchestrate_with_context,
            create_dynamic_goals
        )
        
        context = params.get("context", {})
        goals = params.get("goals", None)
        
        # If no goals provided, create dynamic goals
        if goals is None:
            goals = create_dynamic_goals(context)
        
        result = enhanced_orchestrate_with_context(goals, context)
        return {"ok": True, "result": result}
    except Exception as e:
        return {"ok": False, "error": str(e)}
```

### **Phase 2: CLI Integration (SHORT-TERM)**

#### **Task 2.1: Add CLI Command Wrapper**
Create a generic CLI wrapper that can execute any CLI command:

```python
def tool_empirica_cli_execute(params: Dict[str, Any]) -> Dict[str, Any]:
    """Execute Empirica CLI command"""
    try:
        import subprocess
        
        command = params.get("command")  # e.g., "bootstrap", "assess", "cascade"
        args = params.get("args", [])
        options = params.get("options", {})
        
        # Build CLI command
        cli_cmd = ["python3", "-m", "semantic_self_aware_kit.empirica_cli", command] + args
        
        # Add options as flags
        for key, value in options.items():
            cli_cmd.append(f"--{key}")
            if value is not True:  # Skip value for boolean flags
                cli_cmd.append(str(value))
        
        result = subprocess.run(cli_cmd, capture_output=True, text=True, timeout=120)
        
        return {
            "ok": result.returncode == 0,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "returncode": result.returncode
        }
    except Exception as e:
        return {"ok": False, "error": str(e)}
```

#### **Task 2.2: Add CLI Help Tool**
```python
def tool_empirica_cli_help(params: Dict[str, Any]) -> Dict[str, Any]:
    """Get help for Empirica CLI commands"""
    try:
        command = params.get("command", None)
        
        if command:
            # Get help for specific command
            import subprocess
            result = subprocess.run(
                ["python3", "-m", "semantic_self_aware_kit.empirica_cli", command, "--help"],
                capture_output=True,
                text=True,
                timeout=30
            )
            return {"ok": True, "help": result.stdout}
        else:
            # Get general help
            help_text = """
Empirica CLI Commands:
- bootstrap: Initialize system components
- assess: Run 13-vector self-awareness assessment
- cascade: Execute metacognitive cascade
- investigate: Investigate workspace/code
- performance: Run performance benchmarks
- list: List all components
- demo: Run interactive demos
- feedback: Provide system feedback

Use 'empirica.cli.help' with command parameter for detailed help.
            """
            return {"ok": True, "help": help_text.strip()}
    except Exception as e:
        return {"ok": False, "error": str(e)}
```

### **Phase 3: Tool Registry Update (SHORT-TERM)**

Update the TOOLS dict and TOOL_FUNCS dict in empirica_mcp_server.py:

```python
# Add new tool definitions
TOOLS.update({
    "empirica.cascade.run_full": {
        "name": "empirica.cascade.run_full",
        "description": "Run complete metacognitive cascade (THINK‚ÜíUNCERTAINTY‚ÜíCHECK‚ÜíINVESTIGATE‚ÜíACT)",
        "inputSchema": {
            "type": "object",
            "properties": {
                "question": {"type": "string", "description": "Decision or question to analyze"},
                "context": {"type": "object", "description": "Additional context"}
            },
            "required": ["question"]
        }
    },
    # ... add all other tools
})

# Add function mappings
TOOL_FUNCS.update({
    "empirica.cascade.run_full": tool_empirica_cascade_run_full,
    "empirica.cascade.phase": tool_empirica_cascade_phase,
    "empirica.cascade.feedback": tool_empirica_cascade_feedback,
    "empirica.monitor.assess_12d": tool_empirica_monitor_assess_12d,
    "empirica.monitor.get_summary": tool_empirica_monitor_get_summary,
    "empirica.calibration.assess": tool_empirica_calibration_assess,
    "empirica.goals.orchestrate": tool_empirica_goals_orchestrate,
    "empirica.cli.execute": tool_empirica_cli_execute,
    "empirica.cli.help": tool_empirica_cli_help,
})
```

---

## üß™ TESTING STRATEGY

### **Component Integration Tests**
```bash
# Test cascade integration
echo '{"method":"tools/call","id":1,"params":{"name":"empirica.cascade.run_full","arguments":{"question":"Should I deploy?"}}}' | python3 empirica_mcp_server.py --stdio

# Test 12D monitor integration
echo '{"method":"tools/call","id":2,"params":{"name":"empirica.monitor.assess_12d","arguments":{"ai_id":"test","task_context":{"task":"code_review"}}}}' | python3 empirica_mcp_server.py --stdio

# Test uncertainty calibration
echo '{"method":"tools/call","id":3,"params":{"name":"empirica.calibration.assess","arguments":{"decision_context":"Complex migration"}}}' | python3 empirica_mcp_server.py --stdio

# Test goal orchestration
echo '{"method":"tools/call","id":4,"params":{"name":"empirica.goals.orchestrate","arguments":{"context":{"project":"web_dev"}}}}' | python3 empirica_mcp_server.py --stdio

# Test CLI integration
echo '{"method":"tools/call","id":5,"params":{"name":"empirica.cli.help","arguments":{}}}' | python3 empirica_mcp_server.py --stdio
```

### **End-to-End Workflow Tests**
1. **Decision Making Workflow**
   - cascade.run_full ‚Üí monitor.assess_12d ‚Üí calibration.assess ‚Üí goals.orchestrate

2. **Self-Awareness Workflow**
   - monitor.assess_12d ‚Üí monitor.get_summary ‚Üí cascade.run_full (if uncertainty high)

3. **Learning Workflow**
   - cascade.run_full ‚Üí (action) ‚Üí cascade.feedback ‚Üí calibration.provide_feedback

---

## üìà SUCCESS CRITERIA

### **Phase 1 Complete When:**
- ‚úÖ All 4 core components exposed via MCP tools
- ‚úÖ Tool registry updated with all new tools
- ‚úÖ Basic integration tests passing
- ‚úÖ Error handling implemented

### **Phase 2 Complete When:**
- ‚úÖ CLI commands accessible via MCP
- ‚úÖ Help system working
- ‚úÖ All CLI commands tested via MCP

### **Phase 3 Complete When:**
- ‚úÖ All stub tools either implemented or removed
- ‚úÖ Complete MCP tool documentation
- ‚úÖ End-to-end workflows validated
- ‚úÖ Performance benchmarks established

---

## üìã SUMMARY OF REQUIRED CHANGES

### **Immediate Actions Required**
1. **Add 9 new tool functions** for core components
2. **Update TOOLS dict** with 9+ new tool definitions
3. **Update TOOL_FUNCS dict** with function mappings
4. **Test all new tools** with stdio transport
5. **Document tool usage** with examples

### **Components Status**
- ‚úÖ All components operational and ready for MCP integration
- ‚ùå MCP server needs adaptation to expose components
- üîß Estimated effort: 4-6 hours for complete integration
- üìä Impact: Unlocks full Empirica framework via MCP

### **Priority Order**
1. **üî¥ HIGH**: Metacognitive Cascade (most requested functionality)
2. **üî¥ HIGH**: 12D Monitor (core self-awareness capability)
3. **üü° MEDIUM**: Uncertainty Calibration (partially covered by AugieSDK)
4. **üü° MEDIUM**: Goal Orchestration (advanced feature)
5. **üü¢ LOW**: CLI Integration (convenience wrapper)

---

**END OF SPECIFICATION**

*This document serves as the complete blueprint for integrating all Empirica components into the MCP server. All components are tested and ready; only MCP tool definitions and wrapper functions are needed.*

*Status: Ready for Implementation*  
*Next Action: Begin Phase 1 - Core Component Integration*