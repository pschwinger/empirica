# Unified Epistemic Dashboard - Implementation Roadmap

**Date:** 2025-12-06
**Vision:** One command that shows performance AND validates entire Empirica system
**Implementation:** 4 phases over 2-3 weeks

---

## Executive Summary

### Current State
- ‚úÖ `status.sh` - Shows system metrics
- ‚úÖ `leaderboard.sh` - Shows agent rankings
- ‚ùå No diagnostics (are metrics correct?)
- ‚ùå No action hooks (real-time capture)
- ‚ùå Separate commands (context switching)

### Desired State
- ‚úÖ `empirica.sh` - Unified dashboard + diagnostics
- ‚úÖ Action hooks - Real-time metric capture
- ‚úÖ Architecture validation - Self-checking system
- ‚úÖ Anomaly detection - Automatic alerts
- ‚úÖ Traceability - Every number traceable to source

---

## Phase 1: Unified Dashboard (Week 1 - 2 Days)

### Goal: Merge status.sh + leaderboard.sh into empirica.sh

**Implementation:**
```bash
# New unified command
./empirica.sh              # Full output
./empirica.sh --summary    # Executive summary
./empirica.sh --leaderboard  # Performance only
./empirica.sh --diagnostics  # System health only
./empirica.sh --json       # Machine-readable
./empirica.sh --csv        # Spreadsheet-friendly
```

**Work:**
1. **Code consolidation** (4-6 hours)
   - Merge status.sh + leaderboard.sh into empirica.sh
   - Keep both individual commands as aliases (backward compatibility)
   - Add shared utility functions

2. **Output restructuring** (3-4 hours)
   - Section 1: System Diagnostics (new)
   - Section 2: CASCADE Workflow Health
   - Section 3: Performance Metrics
   - Section 4: System Metrics
   - Section 5: Anomalies & Alerts

3. **Testing** (2 hours)
   - Verify all modes work
   - Check output formatting
   - Validate performance (<3 seconds)

**Files:**
- `empirica.sh` (new unified script, ~600 lines)
- Deprecate: Keep `status.sh` and `leaderboard.sh` as aliases

**Success Criteria:**
- ‚úÖ Single command shows everything
- ‚úÖ All previous metrics still visible
- ‚úÖ System diagnostics section added
- ‚úÖ Execution time <3 seconds
- ‚úÖ Backward compatible (old commands still work)

---

## Phase 2: Architecture Validation Layer (Week 1 - 3 Days)

### Goal: Validate all 9 architectural layers

**Implementation:**

```python
# New module: empirica/diagnostics/architecture_validator.py

class ArchitectureValidator:
    def validate_git_infrastructure(self):
        """Check git refs, notes, commits"""

    def validate_database_integrity(self):
        """Check FK constraints, orphaned records, types"""

    def validate_epistemic_vectors(self):
        """Check all 13 vectors, ranges, patterns"""

    def validate_cascade_workflow(self):
        """Check PREFLIGHT‚ÜíCHECK‚ÜíPOSTFLIGHT completeness"""

    def validate_session_continuity(self):
        """Check handoffs, session chains, data preservation"""

    def validate_goals_subtasks(self):
        """Check completeness, dependencies, links"""

    def validate_handoff_reports(self):
        """Check required fields, git notes, parsing"""

    def validate_action_hooks(self):
        """Check all hooks executable, no failures"""

    def generate_report(self):
        """Return structured validation results"""
```

**Validation Checks (Examples):**

```python
# Git Infrastructure
‚úì Can read all git notes without error
‚úì Session IDs in notes match sessions in DB
‚úì Commit timestamps reasonable
‚úó ALERT: Notes corrupted on session XYZ

# Database
‚úì All foreign keys valid (no orphans)
‚úì All required columns present
‚úì No null in critical fields
‚úó ALERT: Goals without session_id found (5 records)

# Epistemic Vectors
‚úì All 13 vectors present in reflexes
‚úì Values 0.0-1.0 (no outliers)
‚úì Uncertainty correlates with knowledge
‚úó ALERT: Agent ABC has declining learning trend

# CASCADE Workflow
‚úì All sessions have PREFLIGHT
‚úì CHECK count reasonable (max 5 per session)
‚úì All sessions have POSTFLIGHT
‚úó ALERT: Agent XYZ has 12 CHECKs (infinite loop?)
```

**Work:**
1. **Design validation functions** (4-5 hours)
   - One validator per layer
   - Reusable check patterns

2. **Implement validators** (6-8 hours)
   - Write all validation logic
   - Create alerts/warnings
   - Collect results

3. **Integration** (2-3 hours)
   - Hook into empirica.sh
   - Format diagnostic output
   - Add performance metrics

**Files:**
- `empirica/diagnostics/architecture_validator.py` (new, ~400 lines)
- `empirica/diagnostics/__init__.py` (new)
- `empirica.sh` (updated to call validators)

**Success Criteria:**
- ‚úÖ All 9 layers validated
- ‚úÖ Issues detected and reported
- ‚úÖ Validation <1 second
- ‚úÖ Clear alert messages
- ‚úÖ Diagnostics section populated

---

## Phase 3: Action Hooks Integration (Week 2 - 3 Days)

### Goal: Real-time metric capture at source

**Implementation:**

Define 8 core action hooks:

```bash
# CASCADE Workflow Hooks
.empirica/hooks/post-preflight          # After PREFLIGHT vectors written
.empirica/hooks/post-check              # After CHECK decision made
.empirica/hooks/post-postflight         # After POSTFLIGHT assessment

# Session Lifecycle Hooks
.empirica/hooks/post-session-create     # New session created
.empirica/hooks/post-session-end        # Session closing
.empirica/hooks/post-goal-create        # New goal created
.empirica/hooks/post-goal-complete      # Goal finished
.empirica/hooks/post-handoff            # Handoff report written
```

**Hook Template:**

```bash
#!/bin/bash
# Example: post-preflight hook

set -e

SESSION_ID=$1
PHASE=$2
VECTORS=$3  # JSON: {engagement: 0.85, know: 0.7, ...}

# 1. Write to primary: SQLite reflexes table
python3 << 'PYTHON'
import json, sys
from empirica.data.session_database import SessionDatabase

db = SessionDatabase()
vectors = json.loads("""$VECTORS""")
db.write_reflex(
    session_id="$SESSION_ID",
    phase="$PHASE",
    vectors=vectors,
    timestamp=time.time()
)
db.close()
PYTHON

# 2. Backup to git notes
git notes --ref=refs/notes/empirica/checkpoints \
  add -f -m "Phase: $PHASE, Session: $SESSION_ID, Vectors: $VECTORS"

# 3. Log to audit trail
echo "{\"event\": \"$PHASE\", \"session\": \"$SESSION_ID\", \"timestamp\": \"$(date -u +%s)\"}" \
  >> .empirica_reflex_logs/events.jsonl

# 4. Trigger dashboard update (if needed)
python3 scripts/update-metrics.py "$SESSION_ID"

echo "‚úì Metrics captured: $SESSION_ID/$PHASE"
```

**Work:**
1. **Design hook system** (2-3 hours)
   - Identify all trigger points
   - Define hook interface
   - Create hook discovery

2. **Implement hooks** (4-6 hours)
   - Write 8 hook templates
   - Test each hook
   - Add error handling

3. **Integration with CASCADE** (3-4 hours)
   - Wire hooks into workflow
   - Call hooks at right points
   - Handle hook failures gracefully

**Files:**
- `.empirica/hooks/post-preflight` (new, ~40 lines)
- `.empirica/hooks/post-check` (new, ~40 lines)
- `.empirica/hooks/post-postflight` (new, ~40 lines)
- `.empirica/hooks/post-session-*` (3 new, ~40 lines each)
- `.empirica/hooks/post-goal-*` (2 new, ~40 lines each)
- `.empirica/hooks/post-handoff` (new, ~40 lines)
- `empirica/core/hook_manager.py` (new, ~100 lines)

**Success Criteria:**
- ‚úÖ All 8 hooks implemented
- ‚úÖ Hooks fire at correct times
- ‚úÖ Metrics captured in real-time
- ‚úÖ No performance impact (<100ms per hook)
- ‚úÖ Failed hooks don't crash workflow
- ‚úÖ Audit trail complete in JSON logs

---

## Phase 4: Anomaly Detection & Self-Validation (Week 2-3 - 3 Days)

### Goal: Automatic detection of problems

**Implementation:**

```python
# empirica/diagnostics/anomaly_detector.py

class AnomalyDetector:
    def detect_learning_anomalies(self):
        """
        Learning should increase ‚Üí POSTFLIGHT know > PREFLIGHT know
        Flag: decreasing learning (knowledge regression)
        """

    def detect_cascade_anomalies(self):
        """
        CHECK count should be 1-5 per session
        Flag: >10 CHECKs (infinite loop?)
        Flag: 0 CHECKs (skipped decision gate?)
        """

    def detect_uncertainty_anomalies(self):
        """
        Uncertainty should decrease over session
        Flag: increasing uncertainty (getting more confused)
        """

    def detect_engagement_anomalies(self):
        """
        Engagement should stay positive
        Flag: engagement drops (motivation lost)
        """

    def detect_completion_anomalies(self):
        """
        Goals should complete within reasonable time
        Flag: goal stuck (>10 days incomplete)
        """

    def detect_continuity_anomalies(self):
        """
        Handoffs should succeed
        Flag: missing handoff reports
        Flag: session chains broken
        """

    def detect_hook_anomalies(self):
        """
        Hooks should fire consistently
        Flag: missing PREFLIGHT vectors
        Flag: missing POSTFLIGHT assessments
        """
```

**Anomaly Examples:**

```
üö© Claude Sonnet: 5 sessions, 0 completed
   ‚Üí Possible: Sessions not ending properly
   ‚Üí Check: session.end_time being set

üö© Qwen agents: Learning growth near 0
   ‚Üí Possible: Model not learning from experience
   ‚Üí Check: PREFLIGHT vs POSTFLIGHT vectors

üö© storage-flow-test: 20 sessions, all in progress
   ‚Üí Possible: Sessions stuck, not terminating
   ‚Üí Check: Action hook for session-end firing?

üö© Uncertainty INCREASES in POSTFLIGHT
   ‚Üí Possible: Getting more confused
   ‚Üí Check: Agent struggling with topic
```

**Work:**
1. **Design anomalies** (3-4 hours)
   - Define 7-10 key anomalies
   - Set alert thresholds
   - Create detection logic

2. **Implement detectors** (4-6 hours)
   - Write anomaly functions
   - Generate alert messages
   - Calculate severity

3. **Integration** (2-3 hours)
   - Hook into empirica.sh
   - Display anomalies section
   - Make actionable

**Files:**
- `empirica/diagnostics/anomaly_detector.py` (new, ~300 lines)
- `empirica/diagnostics/alerts.py` (new, ~50 lines)
- `empirica.sh` (updated to show anomalies)

**Success Criteria:**
- ‚úÖ 7-10 anomalies detected
- ‚úÖ Clear alert messages
- ‚úÖ Actionable recommendations
- ‚úÖ False positives <5%
- ‚úÖ Performance <500ms

---

## Integration Into CASCADE Workflow

**Where action hooks live in CASCADE:**

```
Session Creation
    ‚Üì
post-session-create hook fires
    ‚Üì
PREFLIGHT Assessment
    ‚Üì
post-preflight hook fires (vectors captured)
    ‚Üì
Investigation (0-N rounds)
    ‚Üì
CHECK Assessment
    ‚Üì
post-check hook fires (decision captured)
    ‚Üì
Decision: Proceed or Investigate More?
    ‚îú‚îÄ If Investigate: ‚Üí loop back
    ‚îî‚îÄ If Proceed: ‚Üí ACT
    ‚Üì
Work Done
    ‚Üì
POSTFLIGHT Assessment
    ‚Üì
post-postflight hook fires (learning measured)
    ‚Üì
Handoff (optional)
    ‚Üì
post-handoff hook fires (continuity captured)
    ‚Üì
Session End
    ‚Üì
post-session-end hook fires (closure confirmed)
```

---

## Unified Dashboard Output Example

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë       EMPIRICA UNIFIED DASHBOARD v2.0 - FULL DIAGNOSTICS           ‚ïë
‚ïë            Status: FULLY OPERATIONAL ‚úì | All Systems Green         ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
1. SYSTEM DIAGNOSTICS
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Git Infrastructure:        ‚úÖ OK | 4 notes refs readable | 48 notes total
Database Integrity:        ‚úÖ OK | 0 orphaned records | All FKs valid
Reflexes Table:            ‚úÖ OK | 13 vectors present | Ranges valid
Session Continuity:        ‚úÖ OK | 90% handoff success | 0 data loss
Action Hooks:              ‚úÖ OK | 8/8 executable | 0 failures

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
2. CASCADE WORKFLOW HEALTH
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Sessions with PREFLIGHT:   199/199 (100%) ‚úÖ
Sessions with CHECK:       187/199 (94%)  ‚ö†Ô∏è (12 missing CHECK)
Sessions with POSTFLIGHT:  199/199 (100%) ‚úÖ
Decision Quality:          ‚úÖ Confidence tracking accurate

CASCADE Pattern: PREFLIGHT ‚Üí [CHECK]* ‚Üí POSTFLIGHT
  Avg CHECKs per session:  0.9 (good, no infinite loops)
  Max CHECKs:              5 (within expected range)
  Learning measurement:    ‚úÖ Complete for 199 sessions

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
3. PERFORMANCE METRICS
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

ü•á  1. empirica_tester        üöÄüß†üî¨üåü   Learning: 0.5    Mastery: 0.7
ü•à  2. test_agent             üöÄ‚ö°üß†üî¨   Learning: 0.225  Mastery: 0.625
ü•â  3. claude-docs-overhaul   üß†üî¨üéì    Learning: 0.157  Mastery: 0.9

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
4. SYSTEM METRICS
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Sessions:       199 total (90 complete 45%) (109 in progress 55%)
Goals:          147 total (85 complete 57%) (62 in progress 43%)
Subtasks:       312 total (205 complete 65%) (107 in progress 35%)
Cascades:       Tracked via hooks (real-time)
Handoffs:       90% success (9/10 complete)

Team Learning:  Avg 0.068 | Max 0.5 | Min -0.5
Team Mastery:   Avg 0.452 | Max 0.95 | Min 0.0

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
5. ANOMALIES & ALERTS
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚ö†Ô∏è  ATTENTION NEEDED:

1. Claude Sonnet: 5 sessions, 0% complete
   ‚Üí Possible: Sessions not terminating properly
   ‚Üí Action: Check post-session-end hook logs

2. storage-flow-test: 20 sessions, 0% complete
   ‚Üí Possible: Systematic issue with session closure
   ‚Üí Action: Review session termination logic

3. Qwen agents: Learning growth near 0 (avg -0.1)
   ‚Üí Possible: Model not learning from experience
   ‚Üí Action: Check PREFLIGHT vs POSTFLIGHT vectors
   ‚Üí Note: May be expected (test agents?)

4. 12 sessions missing CHECK phase
   ‚Üí Possible: Decision gate skipped
   ‚Üí Action: Verify CHECK capture hook firing

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Database: .empirica/sessions/sessions.db (500KB)
Git Notes: refs/notes/empirica/{checkpoints,handoff,sessions} (48 total)
Action Hooks: 8 hooks, last fired 2025-12-06 20:15:31
Audit Trail: 3,247 events logged
Last Updated: 2025-12-06 20:15:45
System Uptime: 12.3 days, 0 critical errors
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

---

## Implementation Timeline

| Phase | Duration | Effort | Owner | Deliverable |
|-------|----------|--------|-------|-------------|
| 1: Unified Dashboard | 2 days | 10-15 hrs | Claude Code | empirica.sh |
| 2: Architecture Validation | 3 days | 15-20 hrs | Claude Sonnet | Validators |
| 3: Action Hooks | 3 days | 12-18 hrs | Qwen | Hooks + integration |
| 4: Anomaly Detection | 3 days | 10-15 hrs | Copilot CLI | Detectors |

**Total:** ~2-3 weeks, ~50-70 hours

---

## Expected Outcome

After all phases:

‚úÖ **One command** shows everything
‚úÖ **Real-time metrics** via action hooks
‚úÖ **System diagnostics** built-in
‚úÖ **Anomaly detection** automatic
‚úÖ **Traceability** complete (everything traceable to source)
‚úÖ **Self-validating** (can detect its own bugs)

**This becomes Empirica's health monitor and bug detector combined.**

---

## Success Criteria

### Phase 1
- ‚úÖ empirica.sh combines status + leaderboard
- ‚úÖ All metrics still visible
- ‚úÖ <3 second execution
- ‚úÖ Backward compatible

### Phase 2
- ‚úÖ All 9 layers validated
- ‚úÖ Issues detected
- ‚úÖ Clear reporting
- ‚úÖ No false positives

### Phase 3
- ‚úÖ All 8 hooks working
- ‚úÖ Real-time capture
- ‚úÖ Audit trail complete
- ‚úÖ No performance impact

### Phase 4
- ‚úÖ 7-10 anomalies detected
- ‚úÖ Clear alerts
- ‚úÖ Actionable recommendations
- ‚úÖ <1 second detection

---

**Status:** Designed and ready for implementation
**Next Step:** Start Phase 1 (merge scripts into unified dashboard)
