# ğŸ§  Empirica - Metacognitive Framework for AI Agents

> Genuine epistemic self-awareness with measurable calibration

[![Status](https://img.shields.io/badge/status-pre--release-orange)]()
[![Python](https://img.shields.io/badge/python-3.8%2B-blue)]()
[![License](https://img.shields.io/badge/license-MIT-green)]()

**97.5% token reduction** â€¢ **Self-referential goals** â€¢ **Production validated**

## What is Empirica?

Empirica enables AI agents to assess their own knowledge, track epistemic growth, and make calibrated decisions. Not just metricsâ€”**genuine self-awareness with measurable calibration**.

**Proven through 73 sessions** across multiple AI agents with validated results:
- ğŸ§  **Self-referential goal generation** - AI reasons about its own goals
- ğŸ“‰ **97.5% token reduction** - Git-enhanced context loading (Phase 1.5)
- ğŸ“Š **13-vector epistemic assessment** - Comprehensive self-evaluation
- âœ… **Well-calibrated growth** - Predictions match reality

**This is empirically testable.** Epistemic growth is measurable and reproducible.

## âœ¨ Key Features

### ğŸ§  Self-Referential Goal Generation
AI agents can now reason about their own goals using `llm_callback`:
```python
def my_ai(prompt: str) -> str:
    return ai_client.reason(prompt)

components = bootstrap_metacognition("agent", "minimal", llm_callback=my_ai)
```
No hardcoded thresholdsâ€”genuine reasoning about context and needs.

### ğŸ“‰ Git-Enhanced Context Loading (Phase 1.5)
**97.5% token reduction** through git notes integration:
- Baseline: ~1,821 tokens (full session history)
- Optimized: 46 tokens (git checkpoint)
- Validated in production with measurable results

### ğŸ“Š 13-Vector Epistemic Assessment
Complete self-evaluation framework:
- **Foundation:** KNOW, DO, CONTEXT
- **Comprehension:** CLARITY, COHERENCE, SIGNAL, DENSITY
- **Execution:** STATE, CHANGE, COMPLETION, IMPACT
- **Meta:** ENGAGEMENT, UNCERTAINTY
- **Calibration:** Overall confidence tracking

### ğŸ”„ CASCADE Workflow
Systematic methodology: PREFLIGHT â†’ INVESTIGATE â†’ CHECK â†’ ACT â†’ POSTFLIGHT
- Measurable learning at each phase
- Well-calibrated predictions
- Transparent decision trails

### ğŸ”— MCP Server Integration
21 tools for epistemic tracking, goal orchestration, and session management.

## Who Uses Empirica?

**ğŸ¤– AI agents** (Claude, GPT, Gemini, etc.) - You're the primary user  
**ğŸ‘¤ Developers** in critical domains - Healthcare, finance, research, engineering  
**ğŸ¢ Teams** requiring AI transparency - Audit trails, calibration metrics, decision logs

âš ï¸ **Not for casual use** - Requires genuine epistemic engagement

## Quick Start

### ğŸ¤– For AI Agents
```bash
empirica onboard --ai-id <your-name>
```
*10-minute interactive learning experience*

**Then:** [`docs/01_a_AI_AGENT_START.md`](docs/01_a_AI_AGENT_START.md)

### ğŸ‘¤ For Human Developers

**Installation:**
```bash
git clone https://github.com/Nubaeon/empirica.git
cd empirica
pip install -e .
```

**Basic usage:**
```python
from empirica.bootstraps import bootstrap_metacognition

# Simple mode (threshold-based goals)
components = bootstrap_metacognition("my-ai", "minimal")

# AI reasoning mode (self-referential goals)
def my_llm(prompt: str) -> str:
    return ai_client.reason(prompt)

components = bootstrap_metacognition(
    ai_id="my-ai",
    level="minimal", 
    llm_callback=my_llm  # AI generates its own goals!
)
```

**Then:** [`docs/02_INSTALLATION.md`](docs/02_INSTALLATION.md) â†’ [`docs/03_CLI_QUICKSTART.md`](docs/03_CLI_QUICKSTART.md)

## Core Workflow

```
PREFLIGHT â†’ Assess what you know/don't know
    â†“
  ACT   â†’ Execute task with awareness
    â†“
POSTFLIGHT â†’ Calibrate: Were you overconfident? Underconfident?
```

**Example:**
```bash
# Before task: Assess your epistemic state
SESSION=$(empirica preflight "debug authentication issue" --quiet)

# Do the work...

# After task: Measure what you learned
empirica postflight $SESSION --summary "fixed OAuth token validation"

# System shows:
# - Epistemic delta (what you actually learned)
# - Calibration quality (predictions vs reality)
```

## Philosophy

**No heuristics.** No calibration shortcuts. No fake confidence scores.

Empirica helps AIs demonstrate *genuine epistemic self-awareness*:
- **What do I actually know?** (evidence-based)
- **What can I actually do?** (capabilities)
- **What am I uncertain about?** (unknowns)
- **What context am I missing?** (blind spots)

High uncertainty is **good** when appropriate. Acknowledge what you don't know.

## Key Features

- ğŸ¯ **12-vector epistemic self-assessment** - KNOW, DO, CONTEXT, CLARITY, COHERENCE, SIGNAL, DENSITY, STATE, CHANGE, COMPLETION, IMPACT, ENGAGEMENT (+ UNCERTAINTY meta-tracking)
- ğŸ”„ **CASCADE workflow** - Preflight â†’ Investigate â†’ Check â†’ Act â†’ Postflight â†’ Synthesize â†’ Learn
- ğŸ“Š **Calibration tracking** - Overconfident vs well-calibrated measurement
- ğŸ”Œ **MCP server** - IDE integration (Claude Desktop, Cursor, Windsurf, Rovo Dev)
- ğŸš **CLI interface** - Direct agent interaction via terminal
- ğŸ“ˆ **Dashboard monitoring** - Real-time epistemic tracking (tmux-based)
- ğŸ” **Bayesian belief tracking** - Detect calibration drift
- ğŸ“ **Session continuity** - Resume previous work with context

## Documentation

**Start here:**
- ğŸ¤– [AI Agent Quick Start](docs/01_a_AI_AGENT_START.md) - Command-line onboarding for AI agents
- ğŸ”Œ [MCP AI Start](docs/01_b_MCP_AI_START.md) - IDE integration (Claude Desktop, Cursor, etc.)

**Production guides:**
- ğŸš€ [Quick Start](docs/production/01_QUICK_START.md)
- ğŸ“¦ [Installation](docs/production/02_INSTALLATION.md)  
- ğŸ¯ [Basic Usage](docs/production/03_BASIC_USAGE.md)
- ğŸ—ï¸ [Architecture Overview](docs/production/04_ARCHITECTURE_OVERVIEW.md)

**Practical examples:**
- ğŸ” [Reasoning Reconstruction](examples/reasoning_reconstruction/) - Extract learning insights from sessions
- ğŸ“¦ [Knowledge Transfer](examples/reasoning_reconstruction/) - Share knowledge between AI agents
- âœ… Works today with core Empirica (no additional dependencies)

**See [`docs/`](docs/) and [`docs/production/`](docs/production/) for complete documentation.**

## Installation

```bash
# Clone repository
git clone https://github.com/Nubaeon/empirica.git
cd empirica

# Install
pip install -e .

# Verify
empirica --version

# Start learning
empirica onboard --ai-id <your-name>
```

**Requirements:** Python 3.8+

**For MCP integration:** See [`docs/04_MCP_QUICKSTART.md`](docs/04_MCP_QUICKSTART.md)

## Example: Real Epistemic Assessment

```bash
# AI agent assesses task before starting
$ empirica preflight "refactor authentication module"

ğŸ“‹ Task: refactor authentication module
ğŸ§  Assessing epistemic state...

Vectors:
  KNOW:        0.75  (Proficient in auth patterns)
  DO:          0.65  (Can refactor with testing)
  CONTEXT:     0.55  (Need to see current implementation)
  UNCERTAINTY: 0.45  (Moderate - depends on tech stack)
  CLARITY:     0.80  (Clear goal, fuzzy scope)

âš ï¸  Recommendation: INVESTIGATE first (CONTEXT low)
ğŸ” Suggested actions:
   - Review current auth implementation
   - Check test coverage
   - Identify dependencies

Session: abc123 (saved)
```

After completing the work:

```bash
$ empirica postflight abc123 --summary "OAuth2 refactor complete"

ğŸ“Š Calibration Report:

Epistemic Delta:
  KNOW:    0.75 â†’ 0.85  (+0.10)  Learned OAuth2 edge cases
  DO:      0.65 â†’ 0.80  (+0.15)  Successful refactor
  CONTEXT: 0.55 â†’ 0.90  (+0.35)  Full codebase understanding

Calibration Quality: WELL-CALIBRATED âœ…
  - Predicted uncertainty matched actual learning
  - Appropriate investigation phase
  - Accurate capability assessment

Session saved with calibration metrics.
```

## Use Cases

### Critical Domain Decision Making
- Healthcare AI requiring "I don't know" acknowledgment
- Financial systems with audit requirements
- Research AI with epistemic rigor
- Engineering decisions with safety implications

### AI Transparency
- Show users what AI knows vs doesn't know
- Demonstrate genuine vs confabulated confidence
- Provide audit trails for AI decisions
- Track calibration over time

### Development Workflows
- Pre-task risk assessment
- Post-task learning measurement
- Investigation loop management
- Session continuity across interruptions

## Core Principles

âœ… **NO HEURISTICS** - Genuine self-assessment only  
âœ… **BE HONEST** - Acknowledge what you don't know  
âœ… **TRACK LEARNING** - Preflight â†’ postflight shows growth  
âœ… **VALIDATE CALIBRATION** - Were your predictions accurate?  
âœ… **EVIDENCE-BASED** - No pattern matching shortcuts

## License

[LICENSE TYPE] - See [LICENSE](LICENSE) file

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md)

## Support

- **ğŸ“– Documentation:** [`docs/README.md`](docs/README.md)
- **ğŸ”§ Troubleshooting:** [`docs/06_TROUBLESHOOTING.md`](docs/06_TROUBLESHOOTING.md)
- **ğŸ’¬ Questions:** Open an issue or ask your AI agent to run `empirica onboard`

---

**Questions?** Start with [`docs/01_a_AI_AGENT_START.md`](docs/01_a_AI_AGENT_START.md) (AI) or [`docs/00_START_HERE.md`](docs/00_START_HERE.md) (Human)

## Enterprise & Research

**Reasoning Reconstruction (Available Now):**
- Extract epistemic learning from sessions
- Generate audit trails with temporal proofs
- Transfer knowledge between AI agents
- Privacy-preserving analysis options

See [`examples/reasoning_reconstruction/`](examples/reasoning_reconstruction/) for working scripts and documentation.

**Semantic Extension (Optional):**
- Vector embeddings for semantic search
- Multi-agent knowledge graphs
- Advanced decision reconstruction
- Enterprise-scale deployments

See [`docs/production/SEMANTIC_REASONING_EXTENSION.md`](docs/production/SEMANTIC_REASONING_EXTENSION.md) for architecture and roadmap.

**Key principle:** Core Empirica is complete. Semantic extension adds convenience, not capability.

