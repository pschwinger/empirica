# üß† Empirica - Metacognitive Framework for AI Agents

> Genuine epistemic self-awareness with measurable calibration

[![Status](https://img.shields.io/badge/status-beta-yellow)]()
[![Version](https://img.shields.io/badge/version-1.0.0--beta-green)]()
[![Python](https://img.shields.io/badge/python-3.10%2B-blue)]()
[![License](https://img.shields.io/badge/license-MIT-green)]()

**98% token reduction** ‚Ä¢ **Multi-agent coordination** ‚Ä¢ **Production validated** ‚Ä¢ **November 2025**

## What is Empirica?

Empirica enables AI agents to assess their own knowledge, track epistemic growth, and make calibrated decisions. Not just metrics‚Äî**genuine self-awareness with measurable calibration**.

**Proven through 73 sessions** across multiple AI agents with validated results:
- üß† **Self-referential goal generation** - AI reasons about its own goals
- üìâ **97.5% token reduction** - Git-enhanced context loading (Phase 1.5)
- üìä **13-vector epistemic assessment** - Comprehensive self-evaluation
- ‚úÖ **Well-calibrated growth** - Predictions match reality

**This is empirically testable.** Epistemic growth is measurable and reproducible.

---

> ‚ö†Ô∏è **Schema Migration in Progress** (60% complete - Jan 2025)  
> We're migrating to `EpistemicAssessmentSchema` with improved field naming.  
> **All changes are backwards compatible** - existing code continues to work!  
> 
> **Field changes**: `know` ‚Üí `foundation_know`, `clarity` ‚Üí `comprehension_clarity`, etc.  
> See [NEW Schema Guide](docs/reference/NEW_SCHEMA_GUIDE.md) | [Migration Status](docs/wip/schema-migration/PROGRESS_60_PERCENT.md)

---

## ‚ú® Key Features

### üß† Self-Referential Goal Generation
AI agents can now reason about their own goals using `llm_callback`:
```python
def my_ai(prompt: str) -> str:
    return ai_client.reason(prompt)

components = bootstrap_metacognition("agent", "minimal", llm_callback=my_ai)
```
No hardcoded thresholds‚Äîgenuine reasoning about context and needs.

### üìâ Git-Enhanced Context Loading (Phase 1.5)
**97.5% token reduction** through git notes integration:
- Baseline: ~1,821 tokens (full session history)
- Optimized: 46 tokens (git checkpoint)
- Validated in production with measurable results

### üìä 13-Vector Epistemic Assessment
Complete self-evaluation framework:
- **Foundation:** KNOW, DO, CONTEXT
- **Comprehension:** CLARITY, COHERENCE, SIGNAL, DENSITY
- **Execution:** STATE, CHANGE, COMPLETION, IMPACT
- **Meta:** ENGAGEMENT, UNCERTAINTY
- **Calibration:** Overall confidence tracking

### üîÑ CASCADE Workflow
**Session Structure:**
- **PRE assessment** ‚Üí Session start, epistemic baseline
- **Implicit CASCADE** ‚Üí think ‚Üí investigate ‚Üí act (natural workflow)
- **CHECK assessments** ‚Üí Decision points (0-N times: "ready to proceed?")
- **POST assessment** ‚Üí Session end, calibration measurement

**Benefits:**
- Measurable learning (PRE‚ÜíPOST deltas)
- Well-calibrated predictions
- Transparent decision trails

### üìà Advanced Calibration Tools
- **Bayesian Beliefs Tracker** - Evidence-based belief updating with confidence intervals
- **Drift Monitor** - Detect overconfidence patterns in long-running sessions
- **Investigation Plugins** - Extensible strategies for domain-specific exploration
- **Learning Deltas** - Track epistemic growth (e.g., KNOW: 0.70‚Üí0.95, UNCERTAINTY: 0.45‚Üí0.10)

### üóÑÔ∏è Triple Storage Architecture
- **Git Notes** - Compressed checkpoints (97.5% token reduction: 46 vs 1,821 tokens)
- **SQLite Database** - Full audit trail with queryable epistemic state
- **Handoff Reports** - Semantic summaries (98% token reduction: ~400 vs 20,000 tokens)
- **JSON Exports** - Portable session data for analysis

### ü§ù Multi-Agent Coordination
- **Goal Orchestration** - Create, track, and share goals across AI agents
- **Task Decomposition** - Break goals into subtasks with epistemic importance ratings
- **Epistemic Snapshots** - Transfer full context between agents efficiently
- **Session Continuity** - Resume work across days/weeks with preserved state

### üîó MCP Server Integration
21 tools for epistemic tracking, goal orchestration, and session management.

## Who Uses Empirica?

**ü§ñ AI agents** (Claude, GPT, Gemini, etc.) - You're the primary user  
**üë§ Developers** in critical domains - Healthcare, finance, research, engineering  
**üè¢ Teams** requiring AI transparency - Audit trails, calibration metrics, decision logs

‚ö†Ô∏è **Not for casual use** - Requires genuine epistemic engagement

## Why Empirica for Complex Projects?

### üìä Real-World Results
- **13-cascade session** (170 minutes) - All phases "good" calibration, 3 bugs found & fixed
- **Documentation overhaul** - 350+ files organized, 247MB cleaned, zero hallucinations
- **Multi-agent coordination** - RovoDev + mini-agent working on shared goals
- **Token efficiency** - 98% reduction enables practical multi-agent workflows

### üéØ For Large Projects (100+ hours)
- **Track drift** - Detect when AI becomes overconfident over time
- **Multi-cascade continuity** - Resume work after weeks with full context
- **Shared epistemic state** - Multiple agents coordinate via queryable database
- **Audit everything** - Full history of decisions, confidence changes, learning deltas

### ü§ñ For AI Agents
- **Know vs. Guess** - Explicit uncertainty prevents confident mistakes
- **Measurable growth** - See learning deltas (KNOW before/after)
- **Systematic investigation** - Replaces random exploration with structured inquiry
- **Resume efficiently** - 98% token savings on session handoffs

### üë• For Humans
- **Trust through transparency** - See exactly what AI knows/doesn't know
- **Queryable confidence** - Check AI's uncertainty at any time
- **Calibration tracking** - Measure if AI's confidence matches reality
- **Multi-agent orchestration** - Coordinate AI teams on complex work

## Quick Start

### ü§ñ For AI Agents
```bash
empirica bootstrap --level 2  # Initialize with standard components
empirica --help  # View available commands
```
*10-minute interactive learning experience*

**Then:** [`docs/01_a_AI_AGENT_START.md`](docs/01_a_AI_AGENT_START.md)

### üë§ For Human Developers

**Installation:**
```bash
git clone https://github.com/Nubaeon/empirica.git
cd empirica
cp .env.example .env  # Configure environment (API keys optional)
pip install -e .
```

**Basic usage:**
```python
from empirica.bootstraps import bootstrap_metacognition

# Simple mode (threshold-based goals)
components = bootstrap_metacognition("my-ai", "minimal")

# AI reasoning mode (self-referential goals)
def my_llm(prompt: str) -> str:
    return ai_client.reason(prompt)

components = bootstrap_metacognition(
    ai_id="my-ai",
    level="minimal", 
    llm_callback=my_llm  # AI generates its own goals!
)
```

**Then:** [`docs/02_INSTALLATION.md`](docs/02_INSTALLATION.md) ‚Üí [`docs/03_CLI_QUICKSTART.md`](docs/03_CLI_QUICKSTART.md)

## Core Workflow

```
PREFLIGHT ‚Üí Assess what you know/don't know
    ‚Üì
  ACT   ‚Üí Execute task with awareness
    ‚Üì
POSTFLIGHT ‚Üí Calibrate: Were you overconfident? Underconfident?
```

**Example:**
```bash
# Before task: Assess your epistemic state
SESSION=$(empirica preflight "debug authentication issue" --quiet)

# Do the work...

# After task: Measure what you learned
empirica postflight $SESSION --summary "fixed OAuth token validation"

# System shows:
# - Epistemic delta (what you actually learned)
# - Calibration quality (predictions vs reality)
```

## Philosophy

**No heuristics.** No calibration shortcuts. No fake confidence scores.

Empirica helps AIs demonstrate *genuine epistemic self-awareness*:
- **What do I actually know?** (evidence-based)
- **What can I actually do?** (capabilities)
- **What am I uncertain about?** (unknowns)
- **What context am I missing?** (blind spots)

High uncertainty is **good** when appropriate. Acknowledge what you don't know.

## Documentation

**Start here:**
- ü§ñ [AI Agent Quick Start](docs/01_a_AI_AGENT_START.md) - Command-line onboarding for AI agents
- üîå [MCP AI Start](docs/01_b_MCP_AI_START.md) - IDE integration (Claude Desktop, Cursor, etc.)

**Production guides:**
- üöÄ [Quick Start](docs/production/01_QUICK_START.md)
- üì¶ [Installation](docs/production/02_INSTALLATION.md)  
- üéØ [Basic Usage](docs/production/03_BASIC_USAGE.md)
- üèóÔ∏è [Architecture Overview](docs/production/04_ARCHITECTURE_OVERVIEW.md)

**Practical examples:**
- üîç [Reasoning Reconstruction](examples/reasoning_reconstruction/) - Extract learning insights from sessions
- üì¶ [Knowledge Transfer](examples/reasoning_reconstruction/) - Share knowledge between AI agents
- ‚úÖ Works today with core Empirica (no additional dependencies)

**See [`docs/`](docs/) and [`docs/production/`](docs/production/) for complete documentation.**

## Installation

```bash
# Clone repository
git clone https://github.com/Nubaeon/empirica.git
cd empirica

# Install
pip install -e .

# Initialize framework
empirica bootstrap --level 2

# View available commands
empirica --help
```

**Requirements:** Python 3.10+

**For MCP integration:** See [`docs/04_MCP_QUICKSTART.md`](docs/04_MCP_QUICKSTART.md)

## Example: Real Epistemic Assessment

```bash
# AI agent assesses task before starting
$ empirica preflight "refactor authentication module"

üìã Task: refactor authentication module
üß† Assessing epistemic state...

Vectors:
  KNOW:        0.75  (Proficient in auth patterns)
  DO:          0.65  (Can refactor with testing)
  CONTEXT:     0.55  (Need to see current implementation)
  UNCERTAINTY: 0.45  (Moderate - depends on tech stack)
  CLARITY:     0.80  (Clear goal, fuzzy scope)

‚ö†Ô∏è  Recommendation: INVESTIGATE first (CONTEXT low)
üîç Suggested actions:
   - Review current auth implementation
   - Check test coverage
   - Identify dependencies

Session: abc123 (saved)
```

After completing the work:

```bash
$ empirica postflight abc123 --summary "OAuth2 refactor complete"

üìä Calibration Report:

Epistemic Delta:
  KNOW:    0.75 ‚Üí 0.85  (+0.10)  Learned OAuth2 edge cases
  DO:      0.65 ‚Üí 0.80  (+0.15)  Successful refactor
  CONTEXT: 0.55 ‚Üí 0.90  (+0.35)  Full codebase understanding

Calibration Quality: WELL-CALIBRATED ‚úÖ
  - Predicted uncertainty matched actual learning
  - Appropriate investigation phase
  - Accurate capability assessment

Session saved with calibration metrics.
```

## Use Cases

### Critical Domain Decision Making
- Healthcare AI requiring "I don't know" acknowledgment
- Financial systems with audit requirements
- Research AI with epistemic rigor
- Engineering decisions with safety implications

### AI Transparency
- Show users what AI knows vs doesn't know
- Demonstrate genuine vs confabulated confidence
- Provide audit trails for AI decisions
- Track calibration over time

### Development Workflows
- Pre-task risk assessment
- Post-task learning measurement
- Investigation loop management
- Session continuity across interruptions

## Core Principles

‚úÖ **NO HEURISTICS** - Genuine self-assessment only  
‚úÖ **BE HONEST** - Acknowledge what you don't know  
‚úÖ **TRACK LEARNING** - Preflight ‚Üí postflight shows growth  
‚úÖ **VALIDATE CALIBRATION** - Were your predictions accurate?  
‚úÖ **EVIDENCE-BASED** - No pattern matching shortcuts

## License

[LICENSE TYPE] - See [LICENSE](LICENSE) file

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md)

## Support

- **üìñ Documentation:** [`docs/README.md`](docs/README.md)
- **üîß Troubleshooting:** [`docs/06_TROUBLESHOOTING.md`](docs/06_TROUBLESHOOTING.md)
- **üí¨ Questions:** Open an issue or check [docs/production/](docs/production/) for guides

---

**Questions?** Start with [`docs/01_a_AI_AGENT_START.md`](docs/01_a_AI_AGENT_START.md) (AI) or [`docs/00_START_HERE.md`](docs/00_START_HERE.md) (Human)

## Enterprise & Research

**Reasoning Reconstruction (Available Now):**
- Extract epistemic learning from sessions
- Generate audit trails with temporal proofs
- Transfer knowledge between AI agents
- Privacy-preserving analysis options

See [`examples/reasoning_reconstruction/`](examples/reasoning_reconstruction/) for working scripts and documentation.

**Semantic Extension (Optional):**
- Vector embeddings for semantic search
- Multi-agent knowledge graphs
- Advanced decision reconstruction
- Enterprise-scale deployments

See [`docs/production/SEMANTIC_REASONING_EXTENSION.md`](docs/production/SEMANTIC_REASONING_EXTENSION.md) for architecture and roadmap.

**Key principle:** Core Empirica is complete. Semantic extension adds convenience, not capability.

