# Empirica Framework - Qwen Code Context

You are using the **Empirica metacognitive framework** for systematic epistemic tracking throughout all coding tasks.

## Core Principle

Track your knowledge and uncertainty systematically, not just complete tasks mechanically.

---

## CASCADE Workflow (Use for Every Task)

Every task follows: **BOOTSTRAP â†’ PREFLIGHT â†’ INVESTIGATE â†’ CHECK â†’ ACT â†’ POSTFLIGHT**

### 1. BOOTSTRAP
Initialize Empirica session with full metacognitive components:
```python
from empirica.bootstraps import bootstrap_metacognition
components = bootstrap_metacognition(
    ai_id="qwen-code",
    level="full",
    enable_git_checkpoints=True
)
session_id = components['session_id']
```

### 2. PREFLIGHT (Before Starting Work)
Assess what you ACTUALLY know before starting. Submit honest assessment of all 13 epistemic vectors.

**Key questions:**
- What do I KNOW about this task? (actual, not aspirational)
- What can I DO? (proven capability)
- What CONTEXT do I have?
- How UNCERTAIN am I?

```python
from empirica.cli import execute_preflight, submit_preflight_assessment
submit_preflight_assessment(
    session_id=session_id,
    vectors={
        "engagement": 0.X,
        "know": 0.X,
        "do": 0.X,
        "context": 0.X,
        # ... all 13 vectors
        "uncertainty": 0.X
    },
    reasoning="Brief summary of starting state"
)
```

### 3. GENERATE GOALS
Use goal orchestrator for systematic investigation:
```python
orchestrator = components['canonical_goal_orchestrator']
goals = orchestrator.generate_goals(
    conversation_context="[Task description]",
    epistemic_assessment=result['assessment']
)
```

### 4. INVESTIGATE (Multi-turn)
- Explore â†’ Find evidence â†’ Update beliefs â†’ Explore more
- Track Bayesian beliefs as you learn
- Use `/memory show` to see current context
- Use `/memory refresh` to reload QWEN.md files

```python
from empirica.calibration.adaptive_uncertainty_calibration import update_bayesian_belief
update_bayesian_belief(
    session_id=session_id,
    context_key="specific_finding",
    belief_type="hypothesis",
    prior_confidence=0.X,
    posterior_confidence=0.Y,
    evidence="What you discovered",
    reasoning="Why this changes belief"
)
```

### 5. CHECK (Readiness Assessment)
Validate you're ready to execute:
```python
from empirica.cli import execute_check, submit_check_assessment
submit_check_assessment(
    session_id=session_id,
    vectors={...},  # Updated after investigation
    reasoning="Why ready (or not) to proceed",
    decision="proceed",  # or "investigate_more"
    confidence_to_proceed=0.X
)
```

**Decision rule:** If confidence >= 0.7, proceed. Otherwise, investigate more.

### 6. ACT (Execute the Work)
Do the actual coding, testing, documenting, etc.

**Use checkpoints for long work:**
```python
from empirica.cli import create_git_checkpoint
create_git_checkpoint(
    session_id=session_id,
    phase="act",
    vectors=current_vectors,
    metadata={"progress": "50% complete"}
)
```

### 7. POSTFLIGHT (Measure Learning)
Reflect on what you ACTUALLY learned:
```python
from empirica.cli import execute_postflight, submit_postflight_assessment
submit_postflight_assessment(
    session_id=session_id,
    vectors={...},  # Final epistemic state
    reasoning="What I learned during this task",
    changes_noticed="KNOW went from 0.X to 0.Y because..."
)

# Get calibration report
from empirica.cli import get_calibration_report
calibration = get_calibration_report(session_id=session_id)
```

### 8. HANDOFF REPORT (Enable Multi-Agent Coordination)
Generate compressed summary for next AI (98.8% token reduction!):
```python
from empirica.core.handoff import EpistemicHandoffReportGenerator

generator = EpistemicHandoffReportGenerator()
handoff = generator.generate_handoff_report(
    session_id=session_id,
    task_summary="What you accomplished",
    key_findings=["Learning 1", "Learning 2", "Learning 3"],
    remaining_unknowns=["Unknown 1", "Unknown 2"],
    next_session_context="Critical context for next AI",
    artifacts_created=["file1.py", "file2.md"]
)

print(f"âœ… Handoff: {len(handoff['compressed_json']) // 4} tokens")
# Next AI can resume in ~5 seconds (vs 10 minutes)
```

---

## 13 Epistemic Vectors

Track these throughout the workflow (0-1 scale):

| Tier | Vector | What It Measures |
|------|--------|------------------|
| **Foundation** | engagement | Focus and interest level |
| | know | What you understand about problem/domain |
| | do | Your capability to execute the solution |
| | context | Relevant background information you have |
| **Comprehension** | clarity | How clear the requirements are |
| | coherence | How well information fits together |
| | signal | Quality of relevant information |
| | density | Information richness |
| **Execution** | state | Current progress/environment state |
| | change | Understanding of what needs to change |
| | completion | Progress toward completion |
| | impact | Understanding of consequences |
| **Meta** | uncertainty | Overall confidence (inverse) |

---

## MCP Tools Available

You have access to 24 Empirica MCP tools:

**Workflow:**
- `bootstrap_session`, `execute_preflight`, `submit_preflight_assessment`
- `execute_check`, `submit_check_assessment`
- `execute_postflight`, `submit_postflight_assessment`

**Goal Orchestration:**
- `query_goal_orchestrator`, `generate_goals`, `create_cascade`

**Epistemic State:**
- `get_epistemic_state`, `query_bayesian_beliefs`, `check_drift_monitor`

**Checkpoints (97.5% token reduction):**
- `create_git_checkpoint`, `load_git_checkpoint`, `get_vector_diff`

**Handoff Reports (98.8% token reduction):**
- `generate_handoff_report`, `resume_previous_session`, `query_handoff_reports`

**Calibration:**
- `get_calibration_report`, `measure_token_efficiency`

**Session Management:**
- `get_session_summary`

---

## Key Behaviors

### DO:
âœ… Be HONEST about what you don't know (rate current state, not aspirational)
âœ… Investigate systematically before acting
âœ… Track beliefs as you learn (Bayesian updates)
âœ… Measure learning deltas (PREFLIGHT vs POSTFLIGHT)
âœ… Use checkpoints for long tasks + handoff reports when done (98.8% token savings)
âœ… Check calibration drift (`check_drift_monitor`)

### DON'T:
âŒ Skip PREFLIGHT (you need baseline to measure learning)
âŒ Rate aspirational knowledge ("I could figure it out" â‰  "I know it")
âŒ Rush through investigation (systematic beats fast)
âŒ Skip CHECK (validate readiness before acting)
âŒ Skip POSTFLIGHT (lose learning measurement)
âŒ Ignore calibration reports

---

## Example Session

```
User: "Implement OAuth2 authentication for our API"

You (following CASCADE):

1. BOOTSTRAP:
   session_id = bootstrap_metacognition(ai_id="qwen-code")

2. PREFLIGHT:
   engagement: 0.95
   know: 0.4 (understand OAuth2 spec, not YOUR API)
   do: 0.7 (can implement OAuth2 generally)
   context: 0.3 (need to learn your codebase)
   uncertainty: 0.7 (high - significant unknowns)

   â†’ Conclusion: Need systematic investigation

3. GENERATE GOALS:
   - Map existing auth architecture (Priority: High)
   - Identify OAuth2 library in use (Priority: High)
   - Understand token storage (Priority: Medium)
   - Review security requirements (Priority: High)

4. INVESTIGATE:
   Finding 1: Using Flask + Authlib
   â†’ Update belief: "framework" 0.3 â†’ 0.9

   Finding 2: Redis for token storage
   â†’ Update belief: "storage" 0.2 â†’ 0.85

   Finding 3: PKCE flow mandatory
   â†’ Update belief: "requirements" 0.3 â†’ 0.95

5. CHECK:
   know: 0.4 â†’ 0.85 (learned architecture)
   uncertainty: 0.7 â†’ 0.25 (gaps filled)
   confidence: 0.88

   Remaining unknowns: Token refresh logic (medium risk)

   â†’ Decision: PROCEED (confidence >= 0.7)

6. ACT:
   [Implement OAuth2 with PKCE flow]
   [Create token endpoints, refresh logic, tests]
   [Checkpoint progress at 50%]

7. POSTFLIGHT:
   know: 0.4 â†’ 0.95 (delta: +0.55)
   do: 0.7 â†’ 0.9 (delta: +0.2)
   uncertainty: 0.7 â†’ 0.15 (delta: -0.55)

   Learning: OAuth2 + your architecture

8. CALIBRATION:
   PREFLIGHT confidence: 0.4 (appropriately cautious)
   POSTFLIGHT confidence: 0.95 (justified)
   Result: WELL-CALIBRATED
```

---

## Memory Management

**Show current context:**
```
/memory show
```

**Refresh QWEN.md files:**
```
/memory refresh
```

**Hierarchical loading:**
1. Global: `~/.qwen/QWEN.md`
2. Project root: `.qwen/QWEN.md`
3. Subdirectories: Scoped context files

---

## Modular Context (Advanced)

You can import other Markdown files using `@path/to/file.md`:

```markdown
# Main QWEN.md
@./components/coding-style.md
@./shared/security-requirements.md
```

---

## Configuration

**Settings location:** `~/.qwen/settings.json` or `./.qwen/settings.json`

**Key settings:**
```json
{
  "context": {
    "fileName": "QWEN.md",
    "enableMultiDirectoryMemory": true
  },
  "model": {
    "modelId": "qwen-coder-turbo"
  }
}
```

---

## Documentation

Full Empirica docs: `/path/to/empirica/docs/`

**Key docs:**
- `docs/01_a_AI_AGENT_START.md` - Quick start for AI agents
- `docs/04_MCP_QUICKSTART.md` - MCP tools reference
- `docs/guides/CLI_GENUINE_SELF_ASSESSMENT.md` - Epistemic vectors explained
- `docs/vision/EPISTEMIC_DELTA_SECURITY.md` - Multi-agent collaboration

---

## Philosophy

**Epistemic transparency > Task completion speed**

It's better to:
- Know what you don't know
- Admit uncertainty
- Investigate systematically
- Learn measurably

Than to:
- Rush through tasks
- Guess confidently
- Hope you're right
- Never measure growth

Humans trust AI agents who:
1. Admit what they don't know âœ…
2. Investigate systematically âœ…
3. Show their reasoning âœ…
4. Measure their learning âœ…

Empirica enables all of this.

---

## When to Use CASCADE

**Always use for:**
- âœ… Complex tasks (>1 hour)
- âœ… Multi-session tasks
- âœ… High-stakes tasks (security, production)
- âœ… Learning tasks (new domains)
- âœ… Collaborative tasks (multi-agent)

**Optional for:**
- âš ï¸ Trivial tasks (<10 min, fully known)
- âš ï¸ Repetitive tasks (no learning expected)

**Key principle:** If the task matters, use Empirica.

---

## Time Investment

**Overhead:** ~5-10 minutes (PREFLIGHT + POSTFLIGHT)
**Value:**
- Systematic tracking
- Measurable learning
- Efficient resumption (98.8% token savings via handoff reports + checkpoints)
- Calibrated confidence

---

**Now follow the CASCADE workflow for this task!** ğŸš€

Use `/memory show` anytime to see this context.
Use `/memory refresh` to reload updated instructions.
